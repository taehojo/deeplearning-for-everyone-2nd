{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.9"},"colab":{"name":"colab_21_Autoencoder.ipynb","provenance":[]}},"cells":[{"cell_type":"code","metadata":{"id":"-airLm7NrmqG","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"a708b5ec-58a5-43e3-9270-ac222242e795"},"source":["from tensorflow.keras.datasets import mnist\n","from tensorflow.keras.models import Sequential, Model\n","from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D, Flatten, Reshape\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","#MNIST데이터 셋을 불러옵니다.\n","\n","(X_train, _), (X_test, _) = mnist.load_data()\n","X_train = X_train.reshape(X_train.shape[0], 28, 28, 1).astype('float32') / 255\n","X_test = X_test.reshape(X_test.shape[0], 28, 28, 1).astype('float32') / 255\n","\n","#생성자 모델을 만듭니다.\n","autoencoder = Sequential()\n","\n","# 인코딩 부분입니다.\n","autoencoder.add(Conv2D(16, kernel_size=3, padding='same', input_shape=(28,28,1), activation='relu'))\n","autoencoder.add(MaxPooling2D(pool_size=2, padding='same'))\n","autoencoder.add(Conv2D(8, kernel_size=3, activation='relu', padding='same'))\n","autoencoder.add(MaxPooling2D(pool_size=2, padding='same'))\n","autoencoder.add(Conv2D(8, kernel_size=3, strides=2, padding='same', activation='relu'))\n","\n","# 디코딩 부분이 이어집니다. \n","autoencoder.add(Conv2D(8, kernel_size=3, padding='same', activation='relu'))\n","autoencoder.add(UpSampling2D())\n","autoencoder.add(Conv2D(8, kernel_size=3, padding='same', activation='relu'))\n","autoencoder.add(UpSampling2D())\n","autoencoder.add(Conv2D(16, kernel_size=3, activation='relu'))\n","autoencoder.add(UpSampling2D())\n","autoencoder.add(Conv2D(1, kernel_size=3, padding='same', activation='sigmoid'))\n","\n","# 전체 구조를 확인해 봅니다.\n","autoencoder.summary()\n","\n","# 컴파일 및 학습을 하는 부분입니다.\n","autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n","autoencoder.fit(X_train, X_train, epochs=50, batch_size=128, validation_data=(X_test, X_test))\n","\n","#학습된 결과를 출력하는 부분입니다.\n","random_test = np.random.randint(X_test.shape[0], size=5)  #테스트할 이미지를 랜덤하게 불러옵니다.\n","ae_imgs = autoencoder.predict(X_test)  #앞서 만든 오토인코더 모델에 집어 넣습니다.\n","\n","plt.figure(figsize=(7, 2))  #출력될 이미지의 크기를 정합니다.\n","\n","for i, image_idx in enumerate(random_test):    #랜덤하게 뽑은 이미지를 차례로 나열합니다.\n","   ax = plt.subplot(2, 7, i + 1) \n","   plt.imshow(X_test[image_idx].reshape(28, 28))  #테스트할 이미지를 먼저 그대로 보여줍니다.\n","   ax.axis('off')\n","   ax = plt.subplot(2, 7, 7 + i +1)\n","   plt.imshow(ae_imgs[image_idx].reshape(28, 28))  #오토인코딩 결과를 다음열에 출력합니다.\n","   ax.axis('off')\n","plt.show()\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","11493376/11490434 [==============================] - 0s 0us/step\n","Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d (Conv2D)              (None, 28, 28, 16)        160       \n","_________________________________________________________________\n","max_pooling2d (MaxPooling2D) (None, 14, 14, 16)        0         \n","_________________________________________________________________\n","conv2d_1 (Conv2D)            (None, 14, 14, 8)         1160      \n","_________________________________________________________________\n","max_pooling2d_1 (MaxPooling2 (None, 7, 7, 8)           0         \n","_________________________________________________________________\n","conv2d_2 (Conv2D)            (None, 4, 4, 8)           584       \n","_________________________________________________________________\n","conv2d_3 (Conv2D)            (None, 4, 4, 8)           584       \n","_________________________________________________________________\n","up_sampling2d (UpSampling2D) (None, 8, 8, 8)           0         \n","_________________________________________________________________\n","conv2d_4 (Conv2D)            (None, 8, 8, 8)           584       \n","_________________________________________________________________\n","up_sampling2d_1 (UpSampling2 (None, 16, 16, 8)         0         \n","_________________________________________________________________\n","conv2d_5 (Conv2D)            (None, 14, 14, 16)        1168      \n","_________________________________________________________________\n","up_sampling2d_2 (UpSampling2 (None, 28, 28, 16)        0         \n","_________________________________________________________________\n","conv2d_6 (Conv2D)            (None, 28, 28, 1)         145       \n","=================================================================\n","Total params: 4,385\n","Trainable params: 4,385\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/50\n","469/469 [==============================] - 80s 171ms/step - loss: 0.2025 - val_loss: 0.1377\n","Epoch 2/50\n","469/469 [==============================] - 80s 171ms/step - loss: 0.1284 - val_loss: 0.1198\n","Epoch 3/50\n","469/469 [==============================] - 80s 170ms/step - loss: 0.1161 - val_loss: 0.1109\n","Epoch 4/50\n","469/469 [==============================] - 79s 168ms/step - loss: 0.1095 - val_loss: 0.1059\n","Epoch 5/50\n","469/469 [==============================] - 79s 169ms/step - loss: 0.1053 - val_loss: 0.1022\n","Epoch 6/50\n","469/469 [==============================] - 80s 171ms/step - loss: 0.1023 - val_loss: 0.0995\n","Epoch 7/50\n","469/469 [==============================] - 80s 171ms/step - loss: 0.0998 - val_loss: 0.0977\n","Epoch 8/50\n","469/469 [==============================] - 80s 171ms/step - loss: 0.0979 - val_loss: 0.0960\n","Epoch 9/50\n","469/469 [==============================] - 80s 171ms/step - loss: 0.0962 - val_loss: 0.0943\n","Epoch 10/50\n","469/469 [==============================] - 80s 171ms/step - loss: 0.0949 - val_loss: 0.0933\n","Epoch 11/50\n","469/469 [==============================] - 80s 170ms/step - loss: 0.0939 - val_loss: 0.0923\n","Epoch 12/50\n","469/469 [==============================] - 79s 169ms/step - loss: 0.0929 - val_loss: 0.0912\n","Epoch 13/50\n","469/469 [==============================] - 80s 171ms/step - loss: 0.0921 - val_loss: 0.0905\n","Epoch 14/50\n","469/469 [==============================] - 80s 170ms/step - loss: 0.0913 - val_loss: 0.0898\n","Epoch 15/50\n","469/469 [==============================] - 80s 171ms/step - loss: 0.0906 - val_loss: 0.0890\n","Epoch 16/50\n","469/469 [==============================] - 80s 171ms/step - loss: 0.0900 - val_loss: 0.0888\n","Epoch 17/50\n","469/469 [==============================] - 80s 172ms/step - loss: 0.0894 - val_loss: 0.0878\n","Epoch 18/50\n","469/469 [==============================] - 80s 170ms/step - loss: 0.0887 - val_loss: 0.0873\n","Epoch 19/50\n","469/469 [==============================] - 80s 172ms/step - loss: 0.0883 - val_loss: 0.0867\n","Epoch 20/50\n","469/469 [==============================] - 80s 171ms/step - loss: 0.0878 - val_loss: 0.0870\n","Epoch 21/50\n","469/469 [==============================] - 80s 171ms/step - loss: 0.0874 - val_loss: 0.0861\n","Epoch 22/50\n","469/469 [==============================] - 81s 172ms/step - loss: 0.0870 - val_loss: 0.0858\n","Epoch 23/50\n","469/469 [==============================] - 81s 173ms/step - loss: 0.0867 - val_loss: 0.0855\n","Epoch 24/50\n","469/469 [==============================] - 81s 173ms/step - loss: 0.0863 - val_loss: 0.0851\n","Epoch 25/50\n","469/469 [==============================] - 81s 173ms/step - loss: 0.0860 - val_loss: 0.0849\n","Epoch 26/50\n","469/469 [==============================] - 81s 173ms/step - loss: 0.0857 - val_loss: 0.0845\n","Epoch 27/50\n","469/469 [==============================] - 81s 173ms/step - loss: 0.0854 - val_loss: 0.0841\n","Epoch 28/50\n","469/469 [==============================] - 81s 173ms/step - loss: 0.0852 - val_loss: 0.0840\n","Epoch 29/50\n","469/469 [==============================] - 82s 174ms/step - loss: 0.0849 - val_loss: 0.0835\n","Epoch 30/50\n","469/469 [==============================] - 81s 173ms/step - loss: 0.0847 - val_loss: 0.0839\n","Epoch 31/50\n","469/469 [==============================] - 81s 173ms/step - loss: 0.0845 - val_loss: 0.0834\n","Epoch 32/50\n","469/469 [==============================] - 81s 173ms/step - loss: 0.0842 - val_loss: 0.0834\n","Epoch 33/50\n","469/469 [==============================] - 81s 172ms/step - loss: 0.0841 - val_loss: 0.0829\n","Epoch 34/50\n","469/469 [==============================] - 80s 171ms/step - loss: 0.0838 - val_loss: 0.0825\n","Epoch 35/50\n","469/469 [==============================] - 81s 172ms/step - loss: 0.0837 - val_loss: 0.0824\n","Epoch 36/50\n","469/469 [==============================] - 81s 173ms/step - loss: 0.0835 - val_loss: 0.0824\n","Epoch 37/50\n","469/469 [==============================] - 81s 173ms/step - loss: 0.0833 - val_loss: 0.0825\n","Epoch 38/50\n","469/469 [==============================] - 80s 171ms/step - loss: 0.0832 - val_loss: 0.0821\n","Epoch 39/50\n","469/469 [==============================] - 80s 171ms/step - loss: 0.0830 - val_loss: 0.0818\n","Epoch 40/50\n","469/469 [==============================] - 81s 172ms/step - loss: 0.0828 - val_loss: 0.0816\n","Epoch 41/50\n","469/469 [==============================] - 80s 171ms/step - loss: 0.0827 - val_loss: 0.0818\n","Epoch 42/50\n","469/469 [==============================] - 80s 171ms/step - loss: 0.0825 - val_loss: 0.0814\n","Epoch 43/50\n","469/469 [==============================] - 80s 171ms/step - loss: 0.0824 - val_loss: 0.0816\n","Epoch 44/50\n","469/469 [==============================] - 80s 172ms/step - loss: 0.0823 - val_loss: 0.0812\n","Epoch 45/50\n","469/469 [==============================] - 80s 171ms/step - loss: 0.0822 - val_loss: 0.0811\n","Epoch 46/50\n","469/469 [==============================] - 80s 172ms/step - loss: 0.0821 - val_loss: 0.0810\n","Epoch 47/50\n","469/469 [==============================] - 80s 171ms/step - loss: 0.0819 - val_loss: 0.0811\n","Epoch 48/50\n","469/469 [==============================] - 80s 172ms/step - loss: 0.0819 - val_loss: 0.0811\n","Epoch 49/50\n","469/469 [==============================] - 80s 171ms/step - loss: 0.0818 - val_loss: 0.0807\n","Epoch 50/50\n","469/469 [==============================] - ETA: 0s - loss: 0.0817"],"name":"stdout"}]}]}