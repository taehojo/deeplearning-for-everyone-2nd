{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"colab":{"name":"colab_12_Wine_Check_and_Stop.ipynb","provenance":[{"file_id":"1FB6RO7iu9GH8Jai-AEFecDcd9c1xpt8_","timestamp":1585422599705}]}},"cells":[{"cell_type":"code","metadata":{"id":"zHWH6BD0g35_","colab_type":"code","outputId":"8a76295a-c529-466d-f2c0-38497f4599dd","executionInfo":{"status":"ok","timestamp":1585422790260,"user_tz":240,"elapsed":28320,"user":{"displayName":"Taeho Jo","photoUrl":"https://lh6.googleusercontent.com/-R0w90jUICh4/AAAAAAAAAAI/AAAAAAAABi8/Vvpvj-kW8KA/s64/photo.jpg","userId":"10835425045255184608"}},"colab":{"resources":{"http://localhost:8080/nbextensions/google.colab/files.js":{"data":"Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7Ci8vIE1heCBhbW91bnQgb2YgdGltZSB0byBibG9jayB3YWl0aW5nIGZvciB0aGUgdXNlci4KY29uc3QgRklMRV9DSEFOR0VfVElNRU9VVF9NUyA9IDMwICogMTAwMDsKCmZ1bmN0aW9uIF91cGxvYWRGaWxlcyhpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IHN0ZXBzID0gdXBsb2FkRmlsZXNTdGVwKGlucHV0SWQsIG91dHB1dElkKTsKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIC8vIENhY2hlIHN0ZXBzIG9uIHRoZSBvdXRwdXRFbGVtZW50IHRvIG1ha2UgaXQgYXZhaWxhYmxlIGZvciB0aGUgbmV4dCBjYWxsCiAgLy8gdG8gdXBsb2FkRmlsZXNDb250aW51ZSBmcm9tIFB5dGhvbi4KICBvdXRwdXRFbGVtZW50LnN0ZXBzID0gc3RlcHM7CgogIHJldHVybiBfdXBsb2FkRmlsZXNDb250aW51ZShvdXRwdXRJZCk7Cn0KCi8vIFRoaXMgaXMgcm91Z2hseSBhbiBhc3luYyBnZW5lcmF0b3IgKG5vdCBzdXBwb3J0ZWQgaW4gdGhlIGJyb3dzZXIgeWV0KSwKLy8gd2hlcmUgdGhlcmUgYXJlIG11bHRpcGxlIGFzeW5jaHJvbm91cyBzdGVwcyBhbmQgdGhlIFB5dGhvbiBzaWRlIGlzIGdvaW5nCi8vIHRvIHBvbGwgZm9yIGNvbXBsZXRpb24gb2YgZWFjaCBzdGVwLgovLyBUaGlzIHVzZXMgYSBQcm9taXNlIHRvIGJsb2NrIHRoZSBweXRob24gc2lkZSBvbiBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcCwKLy8gdGhlbiBwYXNzZXMgdGhlIHJlc3VsdCBvZiB0aGUgcHJldmlvdXMgc3RlcCBhcyB0aGUgaW5wdXQgdG8gdGhlIG5leHQgc3RlcC4KZnVuY3Rpb24gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpIHsKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIGNvbnN0IHN0ZXBzID0gb3V0cHV0RWxlbWVudC5zdGVwczsKCiAgY29uc3QgbmV4dCA9IHN0ZXBzLm5leHQob3V0cHV0RWxlbWVudC5sYXN0UHJvbWlzZVZhbHVlKTsKICByZXR1cm4gUHJvbWlzZS5yZXNvbHZlKG5leHQudmFsdWUucHJvbWlzZSkudGhlbigodmFsdWUpID0+IHsKICAgIC8vIENhY2hlIHRoZSBsYXN0IHByb21pc2UgdmFsdWUgdG8gbWFrZSBpdCBhdmFpbGFibGUgdG8gdGhlIG5leHQKICAgIC8vIHN0ZXAgb2YgdGhlIGdlbmVyYXRvci4KICAgIG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSA9IHZhbHVlOwogICAgcmV0dXJuIG5leHQudmFsdWUucmVzcG9uc2U7CiAgfSk7Cn0KCi8qKgogKiBHZW5lcmF0b3IgZnVuY3Rpb24gd2hpY2ggaXMgY2FsbGVkIGJldHdlZW4gZWFjaCBhc3luYyBzdGVwIG9mIHRoZSB1cGxvYWQKICogcHJvY2Vzcy4KICogQHBhcmFtIHtzdHJpbmd9IGlucHV0SWQgRWxlbWVudCBJRCBvZiB0aGUgaW5wdXQgZmlsZSBwaWNrZXIgZWxlbWVudC4KICogQHBhcmFtIHtzdHJpbmd9IG91dHB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIG91dHB1dCBkaXNwbGF5LgogKiBAcmV0dXJuIHshSXRlcmFibGU8IU9iamVjdD59IEl0ZXJhYmxlIG9mIG5leHQgc3RlcHMuCiAqLwpmdW5jdGlvbiogdXBsb2FkRmlsZXNTdGVwKGlucHV0SWQsIG91dHB1dElkKSB7CiAgY29uc3QgaW5wdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQoaW5wdXRJZCk7CiAgaW5wdXRFbGVtZW50LmRpc2FibGVkID0gZmFsc2U7CgogIGNvbnN0IG91dHB1dEVsZW1lbnQgPSBkb2N1bWVudC5nZXRFbGVtZW50QnlJZChvdXRwdXRJZCk7CiAgb3V0cHV0RWxlbWVudC5pbm5lckhUTUwgPSAnJzsKCiAgY29uc3QgcGlja2VkUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICBpbnB1dEVsZW1lbnQuYWRkRXZlbnRMaXN0ZW5lcignY2hhbmdlJywgKGUpID0+IHsKICAgICAgcmVzb2x2ZShlLnRhcmdldC5maWxlcyk7CiAgICB9KTsKICB9KTsKCiAgY29uc3QgY2FuY2VsID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnYnV0dG9uJyk7CiAgaW5wdXRFbGVtZW50LnBhcmVudEVsZW1lbnQuYXBwZW5kQ2hpbGQoY2FuY2VsKTsKICBjYW5jZWwudGV4dENvbnRlbnQgPSAnQ2FuY2VsIHVwbG9hZCc7CiAgY29uc3QgY2FuY2VsUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICBjYW5jZWwub25jbGljayA9ICgpID0+IHsKICAgICAgcmVzb2x2ZShudWxsKTsKICAgIH07CiAgfSk7CgogIC8vIENhbmNlbCB1cGxvYWQgaWYgdXNlciBoYXNuJ3QgcGlja2VkIGFueXRoaW5nIGluIHRpbWVvdXQuCiAgY29uc3QgdGltZW91dFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgc2V0VGltZW91dCgoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9LCBGSUxFX0NIQU5HRV9USU1FT1VUX01TKTsKICB9KTsKCiAgLy8gV2FpdCBmb3IgdGhlIHVzZXIgdG8gcGljayB0aGUgZmlsZXMuCiAgY29uc3QgZmlsZXMgPSB5aWVsZCB7CiAgICBwcm9taXNlOiBQcm9taXNlLnJhY2UoW3BpY2tlZFByb21pc2UsIHRpbWVvdXRQcm9taXNlLCBjYW5jZWxQcm9taXNlXSksCiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdzdGFydGluZycsCiAgICB9CiAgfTsKCiAgaWYgKCFmaWxlcykgewogICAgcmV0dXJuIHsKICAgICAgcmVzcG9uc2U6IHsKICAgICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICAgIH0KICAgIH07CiAgfQoKICBjYW5jZWwucmVtb3ZlKCk7CgogIC8vIERpc2FibGUgdGhlIGlucHV0IGVsZW1lbnQgc2luY2UgZnVydGhlciBwaWNrcyBhcmUgbm90IGFsbG93ZWQuCiAgaW5wdXRFbGVtZW50LmRpc2FibGVkID0gdHJ1ZTsKCiAgZm9yIChjb25zdCBmaWxlIG9mIGZpbGVzKSB7CiAgICBjb25zdCBsaSA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2xpJyk7CiAgICBsaS5hcHBlbmQoc3BhbihmaWxlLm5hbWUsIHtmb250V2VpZ2h0OiAnYm9sZCd9KSk7CiAgICBsaS5hcHBlbmQoc3BhbigKICAgICAgICBgKCR7ZmlsZS50eXBlIHx8ICduL2EnfSkgLSAke2ZpbGUuc2l6ZX0gYnl0ZXMsIGAgKwogICAgICAgIGBsYXN0IG1vZGlmaWVkOiAkewogICAgICAgICAgICBmaWxlLmxhc3RNb2RpZmllZERhdGUgPyBmaWxlLmxhc3RNb2RpZmllZERhdGUudG9Mb2NhbGVEYXRlU3RyaW5nKCkgOgogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAnbi9hJ30gLSBgKSk7CiAgICBjb25zdCBwZXJjZW50ID0gc3BhbignMCUgZG9uZScpOwogICAgbGkuYXBwZW5kQ2hpbGQocGVyY2VudCk7CgogICAgb3V0cHV0RWxlbWVudC5hcHBlbmRDaGlsZChsaSk7CgogICAgY29uc3QgZmlsZURhdGFQcm9taXNlID0gbmV3IFByb21pc2UoKHJlc29sdmUpID0+IHsKICAgICAgY29uc3QgcmVhZGVyID0gbmV3IEZpbGVSZWFkZXIoKTsKICAgICAgcmVhZGVyLm9ubG9hZCA9IChlKSA9PiB7CiAgICAgICAgcmVzb2x2ZShlLnRhcmdldC5yZXN1bHQpOwogICAgICB9OwogICAgICByZWFkZXIucmVhZEFzQXJyYXlCdWZmZXIoZmlsZSk7CiAgICB9KTsKICAgIC8vIFdhaXQgZm9yIHRoZSBkYXRhIHRvIGJlIHJlYWR5LgogICAgbGV0IGZpbGVEYXRhID0geWllbGQgewogICAgICBwcm9taXNlOiBmaWxlRGF0YVByb21pc2UsCiAgICAgIHJlc3BvbnNlOiB7CiAgICAgICAgYWN0aW9uOiAnY29udGludWUnLAogICAgICB9CiAgICB9OwoKICAgIC8vIFVzZSBhIGNodW5rZWQgc2VuZGluZyB0byBhdm9pZCBtZXNzYWdlIHNpemUgbGltaXRzLiBTZWUgYi82MjExNTY2MC4KICAgIGxldCBwb3NpdGlvbiA9IDA7CiAgICB3aGlsZSAocG9zaXRpb24gPCBmaWxlRGF0YS5ieXRlTGVuZ3RoKSB7CiAgICAgIGNvbnN0IGxlbmd0aCA9IE1hdGgubWluKGZpbGVEYXRhLmJ5dGVMZW5ndGggLSBwb3NpdGlvbiwgTUFYX1BBWUxPQURfU0laRSk7CiAgICAgIGNvbnN0IGNodW5rID0gbmV3IFVpbnQ4QXJyYXkoZmlsZURhdGEsIHBvc2l0aW9uLCBsZW5ndGgpOwogICAgICBwb3NpdGlvbiArPSBsZW5ndGg7CgogICAgICBjb25zdCBiYXNlNjQgPSBidG9hKFN0cmluZy5mcm9tQ2hhckNvZGUuYXBwbHkobnVsbCwgY2h1bmspKTsKICAgICAgeWllbGQgewogICAgICAgIHJlc3BvbnNlOiB7CiAgICAgICAgICBhY3Rpb246ICdhcHBlbmQnLAogICAgICAgICAgZmlsZTogZmlsZS5uYW1lLAogICAgICAgICAgZGF0YTogYmFzZTY0LAogICAgICAgIH0sCiAgICAgIH07CiAgICAgIHBlcmNlbnQudGV4dENvbnRlbnQgPQogICAgICAgICAgYCR7TWF0aC5yb3VuZCgocG9zaXRpb24gLyBmaWxlRGF0YS5ieXRlTGVuZ3RoKSAqIDEwMCl9JSBkb25lYDsKICAgIH0KICB9CgogIC8vIEFsbCBkb25lLgogIHlpZWxkIHsKICAgIHJlc3BvbnNlOiB7CiAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgIH0KICB9Owp9CgpzY29wZS5nb29nbGUgPSBzY29wZS5nb29nbGUgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYiA9IHNjb3BlLmdvb2dsZS5jb2xhYiB8fCB7fTsKc2NvcGUuZ29vZ2xlLmNvbGFiLl9maWxlcyA9IHsKICBfdXBsb2FkRmlsZXMsCiAgX3VwbG9hZEZpbGVzQ29udGludWUsCn07Cn0pKHNlbGYpOwo=","ok":true,"headers":[["content-type","application/javascript"]],"status":200,"status_text":""}},"base_uri":"https://localhost:8080/","height":1000}},"source":["#데이터 입력\n","from google.colab import files\n","uploaded = files.upload()\n","my_data = 'wine.csv'\n","\n","!pip install -q tensorflow-gpu==1.15.0\n","%tensorflow_version 1.x\n","import tensorflow as tf\n","import pandas as pd\n","import numpy\n","import os\n","\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.callbacks import ModelCheckpoint,EarlyStopping\n","\n","# seed 값 설정\n","numpy.random.seed(3)\n","tf.compat.v1.set_random_seed(3)\n","\n","#데이터 적용\n","df_pre = pd.read_csv(my_data, header=None)\n","df = df_pre.sample(frac=0.15)\n","\n","dataset = df.values\n","X = dataset[:,0:12]\n","Y = dataset[:,12]\n","\n","model = Sequential()\n","model.add(Dense(30,  input_dim=12, activation='relu'))\n","model.add(Dense(12, activation='relu'))\n","model.add(Dense(8, activation='relu'))\n","model.add(Dense(1, activation='sigmoid'))\n","\n","model.compile(loss='binary_crossentropy',\n","          optimizer='adam',\n","          metrics=['accuracy'])\n","\n","# 모델 저장 폴더 만들기\n","MODEL_DIR = './model/'\n","if not os.path.exists(MODEL_DIR):\n","   os.mkdir(MODEL_DIR)\n","\n","modelpath=\"./model/{epoch:02d}-{val_loss:.4f}.hdf5\"\n","\n","# 모델 업데이트 및 저장\n","checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', verbose=1, save_best_only=True)\n","\n","# 학습 자동 중단 설정\n","early_stopping_callback = EarlyStopping(monitor='val_loss', patience=100)\n","\n","model.fit(X, Y, validation_split=0.2, epochs=3500, batch_size=500, verbose=0, callbacks=[early_stopping_callback,checkpointer])\n","\n"],"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","     <input type=\"file\" id=\"files-fcaf68fd-6f2f-413f-a89b-014893cb979a\" name=\"files[]\" multiple disabled />\n","     <output id=\"result-fcaf68fd-6f2f-413f-a89b-014893cb979a\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script src=\"/nbextensions/google.colab/files.js\"></script> "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Saving wine.csv to wine (1).csv\n","\n","Epoch 00001: val_loss improved from inf to 0.77885, saving model to ./model/01-0.7789.hdf5\n","\n","Epoch 00002: val_loss improved from 0.77885 to 0.65597, saving model to ./model/02-0.6560.hdf5\n","\n","Epoch 00003: val_loss improved from 0.65597 to 0.55439, saving model to ./model/03-0.5544.hdf5\n","\n","Epoch 00004: val_loss improved from 0.55439 to 0.47245, saving model to ./model/04-0.4725.hdf5\n","\n","Epoch 00005: val_loss improved from 0.47245 to 0.40732, saving model to ./model/05-0.4073.hdf5\n","\n","Epoch 00006: val_loss improved from 0.40732 to 0.36463, saving model to ./model/06-0.3646.hdf5\n","\n","Epoch 00007: val_loss improved from 0.36463 to 0.35405, saving model to ./model/07-0.3540.hdf5\n","\n","Epoch 00008: val_loss did not improve from 0.35405\n","\n","Epoch 00009: val_loss did not improve from 0.35405\n","\n","Epoch 00010: val_loss did not improve from 0.35405\n","\n","Epoch 00011: val_loss did not improve from 0.35405\n","\n","Epoch 00012: val_loss did not improve from 0.35405\n","\n","Epoch 00013: val_loss improved from 0.35405 to 0.33584, saving model to ./model/13-0.3358.hdf5\n","\n","Epoch 00014: val_loss improved from 0.33584 to 0.31417, saving model to ./model/14-0.3142.hdf5\n","\n","Epoch 00015: val_loss improved from 0.31417 to 0.30251, saving model to ./model/15-0.3025.hdf5\n","\n","Epoch 00016: val_loss improved from 0.30251 to 0.29789, saving model to ./model/16-0.2979.hdf5\n","\n","Epoch 00017: val_loss improved from 0.29789 to 0.29572, saving model to ./model/17-0.2957.hdf5\n","\n","Epoch 00018: val_loss improved from 0.29572 to 0.29362, saving model to ./model/18-0.2936.hdf5\n","\n","Epoch 00019: val_loss improved from 0.29362 to 0.29102, saving model to ./model/19-0.2910.hdf5\n","\n","Epoch 00020: val_loss improved from 0.29102 to 0.28852, saving model to ./model/20-0.2885.hdf5\n","\n","Epoch 00021: val_loss improved from 0.28852 to 0.28718, saving model to ./model/21-0.2872.hdf5\n","\n","Epoch 00022: val_loss did not improve from 0.28718\n","\n","Epoch 00023: val_loss did not improve from 0.28718\n","\n","Epoch 00024: val_loss did not improve from 0.28718\n","\n","Epoch 00025: val_loss did not improve from 0.28718\n","\n","Epoch 00026: val_loss did not improve from 0.28718\n","\n","Epoch 00027: val_loss did not improve from 0.28718\n","\n","Epoch 00028: val_loss improved from 0.28718 to 0.28341, saving model to ./model/28-0.2834.hdf5\n","\n","Epoch 00029: val_loss improved from 0.28341 to 0.27921, saving model to ./model/29-0.2792.hdf5\n","\n","Epoch 00030: val_loss improved from 0.27921 to 0.27575, saving model to ./model/30-0.2757.hdf5\n","\n","Epoch 00031: val_loss improved from 0.27575 to 0.27298, saving model to ./model/31-0.2730.hdf5\n","\n","Epoch 00032: val_loss improved from 0.27298 to 0.27081, saving model to ./model/32-0.2708.hdf5\n","\n","Epoch 00033: val_loss improved from 0.27081 to 0.26952, saving model to ./model/33-0.2695.hdf5\n","\n","Epoch 00034: val_loss improved from 0.26952 to 0.26917, saving model to ./model/34-0.2692.hdf5\n","\n","Epoch 00035: val_loss did not improve from 0.26917\n","\n","Epoch 00036: val_loss did not improve from 0.26917\n","\n","Epoch 00037: val_loss improved from 0.26917 to 0.26884, saving model to ./model/37-0.2688.hdf5\n","\n","Epoch 00038: val_loss improved from 0.26884 to 0.26757, saving model to ./model/38-0.2676.hdf5\n","\n","Epoch 00039: val_loss improved from 0.26757 to 0.26556, saving model to ./model/39-0.2656.hdf5\n","\n","Epoch 00040: val_loss improved from 0.26556 to 0.26264, saving model to ./model/40-0.2626.hdf5\n","\n","Epoch 00041: val_loss improved from 0.26264 to 0.26003, saving model to ./model/41-0.2600.hdf5\n","\n","Epoch 00042: val_loss improved from 0.26003 to 0.25765, saving model to ./model/42-0.2577.hdf5\n","\n","Epoch 00043: val_loss improved from 0.25765 to 0.25590, saving model to ./model/43-0.2559.hdf5\n","\n","Epoch 00044: val_loss improved from 0.25590 to 0.25466, saving model to ./model/44-0.2547.hdf5\n","\n","Epoch 00045: val_loss improved from 0.25466 to 0.25361, saving model to ./model/45-0.2536.hdf5\n","\n","Epoch 00046: val_loss improved from 0.25361 to 0.25310, saving model to ./model/46-0.2531.hdf5\n","\n","Epoch 00047: val_loss improved from 0.25310 to 0.25206, saving model to ./model/47-0.2521.hdf5\n","\n","Epoch 00048: val_loss improved from 0.25206 to 0.25010, saving model to ./model/48-0.2501.hdf5\n","\n","Epoch 00049: val_loss improved from 0.25010 to 0.24854, saving model to ./model/49-0.2485.hdf5\n","\n","Epoch 00050: val_loss improved from 0.24854 to 0.24639, saving model to ./model/50-0.2464.hdf5\n","\n","Epoch 00051: val_loss improved from 0.24639 to 0.24441, saving model to ./model/51-0.2444.hdf5\n","\n","Epoch 00052: val_loss improved from 0.24441 to 0.24272, saving model to ./model/52-0.2427.hdf5\n","\n","Epoch 00053: val_loss improved from 0.24272 to 0.24079, saving model to ./model/53-0.2408.hdf5\n","\n","Epoch 00054: val_loss improved from 0.24079 to 0.23919, saving model to ./model/54-0.2392.hdf5\n","\n","Epoch 00055: val_loss improved from 0.23919 to 0.23860, saving model to ./model/55-0.2386.hdf5\n","\n","Epoch 00056: val_loss improved from 0.23860 to 0.23794, saving model to ./model/56-0.2379.hdf5\n","\n","Epoch 00057: val_loss improved from 0.23794 to 0.23705, saving model to ./model/57-0.2371.hdf5\n","\n","Epoch 00058: val_loss improved from 0.23705 to 0.23600, saving model to ./model/58-0.2360.hdf5\n","\n","Epoch 00059: val_loss improved from 0.23600 to 0.23525, saving model to ./model/59-0.2353.hdf5\n","\n","Epoch 00060: val_loss improved from 0.23525 to 0.23414, saving model to ./model/60-0.2341.hdf5\n","\n","Epoch 00061: val_loss improved from 0.23414 to 0.23186, saving model to ./model/61-0.2319.hdf5\n","\n","Epoch 00062: val_loss improved from 0.23186 to 0.22884, saving model to ./model/62-0.2288.hdf5\n","\n","Epoch 00063: val_loss improved from 0.22884 to 0.22624, saving model to ./model/63-0.2262.hdf5\n","\n","Epoch 00064: val_loss improved from 0.22624 to 0.22430, saving model to ./model/64-0.2243.hdf5\n","\n","Epoch 00065: val_loss improved from 0.22430 to 0.22212, saving model to ./model/65-0.2221.hdf5\n","\n","Epoch 00066: val_loss improved from 0.22212 to 0.22140, saving model to ./model/66-0.2214.hdf5\n","\n","Epoch 00067: val_loss did not improve from 0.22140\n","\n","Epoch 00068: val_loss did not improve from 0.22140\n","\n","Epoch 00069: val_loss did not improve from 0.22140\n","\n","Epoch 00070: val_loss improved from 0.22140 to 0.21995, saving model to ./model/70-0.2199.hdf5\n","\n","Epoch 00071: val_loss improved from 0.21995 to 0.21755, saving model to ./model/71-0.2175.hdf5\n","\n","Epoch 00072: val_loss improved from 0.21755 to 0.21507, saving model to ./model/72-0.2151.hdf5\n","\n","Epoch 00073: val_loss improved from 0.21507 to 0.21301, saving model to ./model/73-0.2130.hdf5\n","\n","Epoch 00074: val_loss improved from 0.21301 to 0.21234, saving model to ./model/74-0.2123.hdf5\n","\n","Epoch 00075: val_loss improved from 0.21234 to 0.21136, saving model to ./model/75-0.2114.hdf5\n","\n","Epoch 00076: val_loss improved from 0.21136 to 0.20961, saving model to ./model/76-0.2096.hdf5\n","\n","Epoch 00077: val_loss improved from 0.20961 to 0.20764, saving model to ./model/77-0.2076.hdf5\n","\n","Epoch 00078: val_loss improved from 0.20764 to 0.20586, saving model to ./model/78-0.2059.hdf5\n","\n","Epoch 00079: val_loss improved from 0.20586 to 0.20533, saving model to ./model/79-0.2053.hdf5\n","\n","Epoch 00080: val_loss improved from 0.20533 to 0.20498, saving model to ./model/80-0.2050.hdf5\n","\n","Epoch 00081: val_loss improved from 0.20498 to 0.20386, saving model to ./model/81-0.2039.hdf5\n","\n","Epoch 00082: val_loss improved from 0.20386 to 0.20257, saving model to ./model/82-0.2026.hdf5\n","\n","Epoch 00083: val_loss improved from 0.20257 to 0.20027, saving model to ./model/83-0.2003.hdf5\n","\n","Epoch 00084: val_loss improved from 0.20027 to 0.19785, saving model to ./model/84-0.1978.hdf5\n","\n","Epoch 00085: val_loss did not improve from 0.19785\n","\n","Epoch 00086: val_loss improved from 0.19785 to 0.19769, saving model to ./model/86-0.1977.hdf5\n","\n","Epoch 00087: val_loss improved from 0.19769 to 0.19702, saving model to ./model/87-0.1970.hdf5\n","\n","Epoch 00088: val_loss improved from 0.19702 to 0.19620, saving model to ./model/88-0.1962.hdf5\n","\n","Epoch 00089: val_loss improved from 0.19620 to 0.19443, saving model to ./model/89-0.1944.hdf5\n","\n","Epoch 00090: val_loss improved from 0.19443 to 0.19211, saving model to ./model/90-0.1921.hdf5\n","\n","Epoch 00091: val_loss improved from 0.19211 to 0.19058, saving model to ./model/91-0.1906.hdf5\n","\n","Epoch 00092: val_loss improved from 0.19058 to 0.18972, saving model to ./model/92-0.1897.hdf5\n","\n","Epoch 00093: val_loss improved from 0.18972 to 0.18955, saving model to ./model/93-0.1895.hdf5\n","\n","Epoch 00094: val_loss improved from 0.18955 to 0.18882, saving model to ./model/94-0.1888.hdf5\n","\n","Epoch 00095: val_loss improved from 0.18882 to 0.18801, saving model to ./model/95-0.1880.hdf5\n","\n","Epoch 00096: val_loss improved from 0.18801 to 0.18686, saving model to ./model/96-0.1869.hdf5\n","\n","Epoch 00097: val_loss improved from 0.18686 to 0.18595, saving model to ./model/97-0.1860.hdf5\n","\n","Epoch 00098: val_loss improved from 0.18595 to 0.18518, saving model to ./model/98-0.1852.hdf5\n","\n","Epoch 00099: val_loss did not improve from 0.18518\n","\n","Epoch 00100: val_loss did not improve from 0.18518\n","\n","Epoch 00101: val_loss improved from 0.18518 to 0.18342, saving model to ./model/101-0.1834.hdf5\n","\n","Epoch 00102: val_loss improved from 0.18342 to 0.18286, saving model to ./model/102-0.1829.hdf5\n","\n","Epoch 00103: val_loss improved from 0.18286 to 0.18178, saving model to ./model/103-0.1818.hdf5\n","\n","Epoch 00104: val_loss improved from 0.18178 to 0.17905, saving model to ./model/104-0.1791.hdf5\n","\n","Epoch 00105: val_loss improved from 0.17905 to 0.17636, saving model to ./model/105-0.1764.hdf5\n","\n","Epoch 00106: val_loss improved from 0.17636 to 0.17482, saving model to ./model/106-0.1748.hdf5\n","\n","Epoch 00107: val_loss improved from 0.17482 to 0.17429, saving model to ./model/107-0.1743.hdf5\n","\n","Epoch 00108: val_loss did not improve from 0.17429\n","\n","Epoch 00109: val_loss did not improve from 0.17429\n","\n","Epoch 00110: val_loss did not improve from 0.17429\n","\n","Epoch 00111: val_loss did not improve from 0.17429\n","\n","Epoch 00112: val_loss improved from 0.17429 to 0.17121, saving model to ./model/112-0.1712.hdf5\n","\n","Epoch 00113: val_loss improved from 0.17121 to 0.17058, saving model to ./model/113-0.1706.hdf5\n","\n","Epoch 00114: val_loss did not improve from 0.17058\n","\n","Epoch 00115: val_loss did not improve from 0.17058\n","\n","Epoch 00116: val_loss did not improve from 0.17058\n","\n","Epoch 00117: val_loss improved from 0.17058 to 0.17051, saving model to ./model/117-0.1705.hdf5\n","\n","Epoch 00118: val_loss improved from 0.17051 to 0.16791, saving model to ./model/118-0.1679.hdf5\n","\n","Epoch 00119: val_loss improved from 0.16791 to 0.16758, saving model to ./model/119-0.1676.hdf5\n","\n","Epoch 00120: val_loss did not improve from 0.16758\n","\n","Epoch 00121: val_loss improved from 0.16758 to 0.16705, saving model to ./model/121-0.1670.hdf5\n","\n","Epoch 00122: val_loss improved from 0.16705 to 0.16645, saving model to ./model/122-0.1665.hdf5\n","\n","Epoch 00123: val_loss improved from 0.16645 to 0.16645, saving model to ./model/123-0.1664.hdf5\n","\n","Epoch 00124: val_loss improved from 0.16645 to 0.16581, saving model to ./model/124-0.1658.hdf5\n","\n","Epoch 00125: val_loss did not improve from 0.16581\n","\n","Epoch 00126: val_loss did not improve from 0.16581\n","\n","Epoch 00127: val_loss improved from 0.16581 to 0.16557, saving model to ./model/127-0.1656.hdf5\n","\n","Epoch 00128: val_loss did not improve from 0.16557\n","\n","Epoch 00129: val_loss did not improve from 0.16557\n","\n","Epoch 00130: val_loss did not improve from 0.16557\n","\n","Epoch 00131: val_loss improved from 0.16557 to 0.16547, saving model to ./model/131-0.1655.hdf5\n","\n","Epoch 00132: val_loss improved from 0.16547 to 0.16287, saving model to ./model/132-0.1629.hdf5\n","\n","Epoch 00133: val_loss improved from 0.16287 to 0.16090, saving model to ./model/133-0.1609.hdf5\n","\n","Epoch 00134: val_loss improved from 0.16090 to 0.15995, saving model to ./model/134-0.1599.hdf5\n","\n","Epoch 00135: val_loss improved from 0.15995 to 0.15830, saving model to ./model/135-0.1583.hdf5\n","\n","Epoch 00136: val_loss did not improve from 0.15830\n","\n","Epoch 00137: val_loss did not improve from 0.15830\n","\n","Epoch 00138: val_loss did not improve from 0.15830\n","\n","Epoch 00139: val_loss did not improve from 0.15830\n","\n","Epoch 00140: val_loss did not improve from 0.15830\n","\n","Epoch 00141: val_loss improved from 0.15830 to 0.15798, saving model to ./model/141-0.1580.hdf5\n","\n","Epoch 00142: val_loss improved from 0.15798 to 0.15680, saving model to ./model/142-0.1568.hdf5\n","\n","Epoch 00143: val_loss did not improve from 0.15680\n","\n","Epoch 00144: val_loss did not improve from 0.15680\n","\n","Epoch 00145: val_loss did not improve from 0.15680\n","\n","Epoch 00146: val_loss did not improve from 0.15680\n","\n","Epoch 00147: val_loss improved from 0.15680 to 0.15650, saving model to ./model/147-0.1565.hdf5\n","\n","Epoch 00148: val_loss improved from 0.15650 to 0.15444, saving model to ./model/148-0.1544.hdf5\n","\n","Epoch 00149: val_loss improved from 0.15444 to 0.15416, saving model to ./model/149-0.1542.hdf5\n","\n","Epoch 00150: val_loss did not improve from 0.15416\n","\n","Epoch 00151: val_loss did not improve from 0.15416\n","\n","Epoch 00152: val_loss did not improve from 0.15416\n","\n","Epoch 00153: val_loss did not improve from 0.15416\n","\n","Epoch 00154: val_loss improved from 0.15416 to 0.15180, saving model to ./model/154-0.1518.hdf5\n","\n","Epoch 00155: val_loss did not improve from 0.15180\n","\n","Epoch 00156: val_loss did not improve from 0.15180\n","\n","Epoch 00157: val_loss did not improve from 0.15180\n","\n","Epoch 00158: val_loss did not improve from 0.15180\n","\n","Epoch 00159: val_loss did not improve from 0.15180\n","\n","Epoch 00160: val_loss did not improve from 0.15180\n","\n","Epoch 00161: val_loss did not improve from 0.15180\n","\n","Epoch 00162: val_loss did not improve from 0.15180\n","\n","Epoch 00163: val_loss did not improve from 0.15180\n","\n","Epoch 00164: val_loss did not improve from 0.15180\n","\n","Epoch 00165: val_loss improved from 0.15180 to 0.14982, saving model to ./model/165-0.1498.hdf5\n","\n","Epoch 00166: val_loss improved from 0.14982 to 0.14892, saving model to ./model/166-0.1489.hdf5\n","\n","Epoch 00167: val_loss did not improve from 0.14892\n","\n","Epoch 00168: val_loss did not improve from 0.14892\n","\n","Epoch 00169: val_loss did not improve from 0.14892\n","\n","Epoch 00170: val_loss did not improve from 0.14892\n","\n","Epoch 00171: val_loss improved from 0.14892 to 0.14749, saving model to ./model/171-0.1475.hdf5\n","\n","Epoch 00172: val_loss improved from 0.14749 to 0.14517, saving model to ./model/172-0.1452.hdf5\n","\n","Epoch 00173: val_loss did not improve from 0.14517\n","\n","Epoch 00174: val_loss did not improve from 0.14517\n","\n","Epoch 00175: val_loss did not improve from 0.14517\n","\n","Epoch 00176: val_loss did not improve from 0.14517\n","\n","Epoch 00177: val_loss improved from 0.14517 to 0.14245, saving model to ./model/177-0.1425.hdf5\n","\n","Epoch 00178: val_loss improved from 0.14245 to 0.14102, saving model to ./model/178-0.1410.hdf5\n","\n","Epoch 00179: val_loss did not improve from 0.14102\n","\n","Epoch 00180: val_loss did not improve from 0.14102\n","\n","Epoch 00181: val_loss did not improve from 0.14102\n","\n","Epoch 00182: val_loss did not improve from 0.14102\n","\n","Epoch 00183: val_loss did not improve from 0.14102\n","\n","Epoch 00184: val_loss improved from 0.14102 to 0.14072, saving model to ./model/184-0.1407.hdf5\n","\n","Epoch 00185: val_loss did not improve from 0.14072\n","\n","Epoch 00186: val_loss did not improve from 0.14072\n","\n","Epoch 00187: val_loss did not improve from 0.14072\n","\n","Epoch 00188: val_loss did not improve from 0.14072\n","\n","Epoch 00189: val_loss did not improve from 0.14072\n","\n","Epoch 00190: val_loss did not improve from 0.14072\n","\n","Epoch 00191: val_loss did not improve from 0.14072\n","\n","Epoch 00192: val_loss did not improve from 0.14072\n","\n","Epoch 00193: val_loss did not improve from 0.14072\n","\n","Epoch 00194: val_loss did not improve from 0.14072\n","\n","Epoch 00195: val_loss did not improve from 0.14072\n","\n","Epoch 00196: val_loss did not improve from 0.14072\n","\n","Epoch 00197: val_loss did not improve from 0.14072\n","\n","Epoch 00198: val_loss did not improve from 0.14072\n","\n","Epoch 00199: val_loss improved from 0.14072 to 0.13898, saving model to ./model/199-0.1390.hdf5\n","\n","Epoch 00200: val_loss did not improve from 0.13898\n","\n","Epoch 00201: val_loss did not improve from 0.13898\n","\n","Epoch 00202: val_loss did not improve from 0.13898\n","\n","Epoch 00203: val_loss did not improve from 0.13898\n","\n","Epoch 00204: val_loss improved from 0.13898 to 0.13889, saving model to ./model/204-0.1389.hdf5\n","\n","Epoch 00205: val_loss improved from 0.13889 to 0.13874, saving model to ./model/205-0.1387.hdf5\n","\n","Epoch 00206: val_loss did not improve from 0.13874\n","\n","Epoch 00207: val_loss improved from 0.13874 to 0.13859, saving model to ./model/207-0.1386.hdf5\n","\n","Epoch 00208: val_loss improved from 0.13859 to 0.13770, saving model to ./model/208-0.1377.hdf5\n","\n","Epoch 00209: val_loss did not improve from 0.13770\n","\n","Epoch 00210: val_loss did not improve from 0.13770\n","\n","Epoch 00211: val_loss did not improve from 0.13770\n","\n","Epoch 00212: val_loss did not improve from 0.13770\n","\n","Epoch 00213: val_loss improved from 0.13770 to 0.13654, saving model to ./model/213-0.1365.hdf5\n","\n","Epoch 00214: val_loss improved from 0.13654 to 0.13463, saving model to ./model/214-0.1346.hdf5\n","\n","Epoch 00215: val_loss improved from 0.13463 to 0.13304, saving model to ./model/215-0.1330.hdf5\n","\n","Epoch 00216: val_loss did not improve from 0.13304\n","\n","Epoch 00217: val_loss did not improve from 0.13304\n","\n","Epoch 00218: val_loss did not improve from 0.13304\n","\n","Epoch 00219: val_loss did not improve from 0.13304\n","\n","Epoch 00220: val_loss did not improve from 0.13304\n","\n","Epoch 00221: val_loss did not improve from 0.13304\n","\n","Epoch 00222: val_loss did not improve from 0.13304\n","\n","Epoch 00223: val_loss did not improve from 0.13304\n","\n","Epoch 00224: val_loss did not improve from 0.13304\n","\n","Epoch 00225: val_loss did not improve from 0.13304\n","\n","Epoch 00226: val_loss improved from 0.13304 to 0.13096, saving model to ./model/226-0.1310.hdf5\n","\n","Epoch 00227: val_loss improved from 0.13096 to 0.13016, saving model to ./model/227-0.1302.hdf5\n","\n","Epoch 00228: val_loss did not improve from 0.13016\n","\n","Epoch 00229: val_loss did not improve from 0.13016\n","\n","Epoch 00230: val_loss did not improve from 0.13016\n","\n","Epoch 00231: val_loss did not improve from 0.13016\n","\n","Epoch 00232: val_loss improved from 0.13016 to 0.12898, saving model to ./model/232-0.1290.hdf5\n","\n","Epoch 00233: val_loss did not improve from 0.12898\n","\n","Epoch 00234: val_loss did not improve from 0.12898\n","\n","Epoch 00235: val_loss did not improve from 0.12898\n","\n","Epoch 00236: val_loss did not improve from 0.12898\n","\n","Epoch 00237: val_loss improved from 0.12898 to 0.12850, saving model to ./model/237-0.1285.hdf5\n","\n","Epoch 00238: val_loss did not improve from 0.12850\n","\n","Epoch 00239: val_loss did not improve from 0.12850\n","\n","Epoch 00240: val_loss did not improve from 0.12850\n","\n","Epoch 00241: val_loss did not improve from 0.12850\n","\n","Epoch 00242: val_loss improved from 0.12850 to 0.12848, saving model to ./model/242-0.1285.hdf5\n","\n","Epoch 00243: val_loss improved from 0.12848 to 0.12819, saving model to ./model/243-0.1282.hdf5\n","\n","Epoch 00244: val_loss improved from 0.12819 to 0.12773, saving model to ./model/244-0.1277.hdf5\n","\n","Epoch 00245: val_loss improved from 0.12773 to 0.12607, saving model to ./model/245-0.1261.hdf5\n","\n","Epoch 00246: val_loss improved from 0.12607 to 0.12535, saving model to ./model/246-0.1254.hdf5\n","\n","Epoch 00247: val_loss did not improve from 0.12535\n","\n","Epoch 00248: val_loss did not improve from 0.12535\n","\n","Epoch 00249: val_loss did not improve from 0.12535\n","\n","Epoch 00250: val_loss did not improve from 0.12535\n","\n","Epoch 00251: val_loss did not improve from 0.12535\n","\n","Epoch 00252: val_loss improved from 0.12535 to 0.12512, saving model to ./model/252-0.1251.hdf5\n","\n","Epoch 00253: val_loss did not improve from 0.12512\n","\n","Epoch 00254: val_loss did not improve from 0.12512\n","\n","Epoch 00255: val_loss did not improve from 0.12512\n","\n","Epoch 00256: val_loss did not improve from 0.12512\n","\n","Epoch 00257: val_loss improved from 0.12512 to 0.12316, saving model to ./model/257-0.1232.hdf5\n","\n","Epoch 00258: val_loss improved from 0.12316 to 0.12280, saving model to ./model/258-0.1228.hdf5\n","\n","Epoch 00259: val_loss did not improve from 0.12280\n","\n","Epoch 00260: val_loss did not improve from 0.12280\n","\n","Epoch 00261: val_loss did not improve from 0.12280\n","\n","Epoch 00262: val_loss improved from 0.12280 to 0.12234, saving model to ./model/262-0.1223.hdf5\n","\n","Epoch 00263: val_loss improved from 0.12234 to 0.12025, saving model to ./model/263-0.1202.hdf5\n","\n","Epoch 00264: val_loss did not improve from 0.12025\n","\n","Epoch 00265: val_loss did not improve from 0.12025\n","\n","Epoch 00266: val_loss did not improve from 0.12025\n","\n","Epoch 00267: val_loss did not improve from 0.12025\n","\n","Epoch 00268: val_loss improved from 0.12025 to 0.11980, saving model to ./model/268-0.1198.hdf5\n","\n","Epoch 00269: val_loss improved from 0.11980 to 0.11903, saving model to ./model/269-0.1190.hdf5\n","\n","Epoch 00270: val_loss did not improve from 0.11903\n","\n","Epoch 00271: val_loss did not improve from 0.11903\n","\n","Epoch 00272: val_loss did not improve from 0.11903\n","\n","Epoch 00273: val_loss did not improve from 0.11903\n","\n","Epoch 00274: val_loss did not improve from 0.11903\n","\n","Epoch 00275: val_loss did not improve from 0.11903\n","\n","Epoch 00276: val_loss did not improve from 0.11903\n","\n","Epoch 00277: val_loss did not improve from 0.11903\n","\n","Epoch 00278: val_loss improved from 0.11903 to 0.11808, saving model to ./model/278-0.1181.hdf5\n","\n","Epoch 00279: val_loss improved from 0.11808 to 0.11807, saving model to ./model/279-0.1181.hdf5\n","\n","Epoch 00280: val_loss did not improve from 0.11807\n","\n","Epoch 00281: val_loss did not improve from 0.11807\n","\n","Epoch 00282: val_loss did not improve from 0.11807\n","\n","Epoch 00283: val_loss improved from 0.11807 to 0.11632, saving model to ./model/283-0.1163.hdf5\n","\n","Epoch 00284: val_loss did not improve from 0.11632\n","\n","Epoch 00285: val_loss did not improve from 0.11632\n","\n","Epoch 00286: val_loss did not improve from 0.11632\n","\n","Epoch 00287: val_loss improved from 0.11632 to 0.11516, saving model to ./model/287-0.1152.hdf5\n","\n","Epoch 00288: val_loss did not improve from 0.11516\n","\n","Epoch 00289: val_loss did not improve from 0.11516\n","\n","Epoch 00290: val_loss did not improve from 0.11516\n","\n","Epoch 00291: val_loss did not improve from 0.11516\n","\n","Epoch 00292: val_loss did not improve from 0.11516\n","\n","Epoch 00293: val_loss did not improve from 0.11516\n","\n","Epoch 00294: val_loss did not improve from 0.11516\n","\n","Epoch 00295: val_loss did not improve from 0.11516\n","\n","Epoch 00296: val_loss did not improve from 0.11516\n","\n","Epoch 00297: val_loss did not improve from 0.11516\n","\n","Epoch 00298: val_loss did not improve from 0.11516\n","\n","Epoch 00299: val_loss did not improve from 0.11516\n","\n","Epoch 00300: val_loss improved from 0.11516 to 0.11453, saving model to ./model/300-0.1145.hdf5\n","\n","Epoch 00301: val_loss did not improve from 0.11453\n","\n","Epoch 00302: val_loss did not improve from 0.11453\n","\n","Epoch 00303: val_loss improved from 0.11453 to 0.11274, saving model to ./model/303-0.1127.hdf5\n","\n","Epoch 00304: val_loss improved from 0.11274 to 0.11260, saving model to ./model/304-0.1126.hdf5\n","\n","Epoch 00305: val_loss did not improve from 0.11260\n","\n","Epoch 00306: val_loss did not improve from 0.11260\n","\n","Epoch 00307: val_loss did not improve from 0.11260\n","\n","Epoch 00308: val_loss did not improve from 0.11260\n","\n","Epoch 00309: val_loss did not improve from 0.11260\n","\n","Epoch 00310: val_loss did not improve from 0.11260\n","\n","Epoch 00311: val_loss did not improve from 0.11260\n","\n","Epoch 00312: val_loss did not improve from 0.11260\n","\n","Epoch 00313: val_loss did not improve from 0.11260\n","\n","Epoch 00314: val_loss improved from 0.11260 to 0.11122, saving model to ./model/314-0.1112.hdf5\n","\n","Epoch 00315: val_loss did not improve from 0.11122\n","\n","Epoch 00316: val_loss did not improve from 0.11122\n","\n","Epoch 00317: val_loss improved from 0.11122 to 0.11062, saving model to ./model/317-0.1106.hdf5\n","\n","Epoch 00318: val_loss improved from 0.11062 to 0.10856, saving model to ./model/318-0.1086.hdf5\n","\n","Epoch 00319: val_loss did not improve from 0.10856\n","\n","Epoch 00320: val_loss did not improve from 0.10856\n","\n","Epoch 00321: val_loss did not improve from 0.10856\n","\n","Epoch 00322: val_loss did not improve from 0.10856\n","\n","Epoch 00323: val_loss did not improve from 0.10856\n","\n","Epoch 00324: val_loss did not improve from 0.10856\n","\n","Epoch 00325: val_loss did not improve from 0.10856\n","\n","Epoch 00326: val_loss did not improve from 0.10856\n","\n","Epoch 00327: val_loss did not improve from 0.10856\n","\n","Epoch 00328: val_loss did not improve from 0.10856\n","\n","Epoch 00329: val_loss improved from 0.10856 to 0.10853, saving model to ./model/329-0.1085.hdf5\n","\n","Epoch 00330: val_loss did not improve from 0.10853\n","\n","Epoch 00331: val_loss did not improve from 0.10853\n","\n","Epoch 00332: val_loss did not improve from 0.10853\n","\n","Epoch 00333: val_loss improved from 0.10853 to 0.10790, saving model to ./model/333-0.1079.hdf5\n","\n","Epoch 00334: val_loss improved from 0.10790 to 0.10711, saving model to ./model/334-0.1071.hdf5\n","\n","Epoch 00335: val_loss did not improve from 0.10711\n","\n","Epoch 00336: val_loss did not improve from 0.10711\n","\n","Epoch 00337: val_loss did not improve from 0.10711\n","\n","Epoch 00338: val_loss did not improve from 0.10711\n","\n","Epoch 00339: val_loss improved from 0.10711 to 0.10646, saving model to ./model/339-0.1065.hdf5\n","\n","Epoch 00340: val_loss did not improve from 0.10646\n","\n","Epoch 00341: val_loss did not improve from 0.10646\n","\n","Epoch 00342: val_loss did not improve from 0.10646\n","\n","Epoch 00343: val_loss improved from 0.10646 to 0.10428, saving model to ./model/343-0.1043.hdf5\n","\n","Epoch 00344: val_loss did not improve from 0.10428\n","\n","Epoch 00345: val_loss did not improve from 0.10428\n","\n","Epoch 00346: val_loss did not improve from 0.10428\n","\n","Epoch 00347: val_loss improved from 0.10428 to 0.10316, saving model to ./model/347-0.1032.hdf5\n","\n","Epoch 00348: val_loss did not improve from 0.10316\n","\n","Epoch 00349: val_loss did not improve from 0.10316\n","\n","Epoch 00350: val_loss did not improve from 0.10316\n","\n","Epoch 00351: val_loss improved from 0.10316 to 0.10302, saving model to ./model/351-0.1030.hdf5\n","\n","Epoch 00352: val_loss improved from 0.10302 to 0.10249, saving model to ./model/352-0.1025.hdf5\n","\n","Epoch 00353: val_loss did not improve from 0.10249\n","\n","Epoch 00354: val_loss did not improve from 0.10249\n","\n","Epoch 00355: val_loss did not improve from 0.10249\n","\n","Epoch 00356: val_loss improved from 0.10249 to 0.10171, saving model to ./model/356-0.1017.hdf5\n","\n","Epoch 00357: val_loss did not improve from 0.10171\n","\n","Epoch 00358: val_loss did not improve from 0.10171\n","\n","Epoch 00359: val_loss did not improve from 0.10171\n","\n","Epoch 00360: val_loss improved from 0.10171 to 0.10158, saving model to ./model/360-0.1016.hdf5\n","\n","Epoch 00361: val_loss did not improve from 0.10158\n","\n","Epoch 00362: val_loss did not improve from 0.10158\n","\n","Epoch 00363: val_loss did not improve from 0.10158\n","\n","Epoch 00364: val_loss did not improve from 0.10158\n","\n","Epoch 00365: val_loss improved from 0.10158 to 0.10063, saving model to ./model/365-0.1006.hdf5\n","\n","Epoch 00366: val_loss did not improve from 0.10063\n","\n","Epoch 00367: val_loss did not improve from 0.10063\n","\n","Epoch 00368: val_loss did not improve from 0.10063\n","\n","Epoch 00369: val_loss improved from 0.10063 to 0.10000, saving model to ./model/369-0.1000.hdf5\n","\n","Epoch 00370: val_loss did not improve from 0.10000\n","\n","Epoch 00371: val_loss did not improve from 0.10000\n","\n","Epoch 00372: val_loss did not improve from 0.10000\n","\n","Epoch 00373: val_loss did not improve from 0.10000\n","\n","Epoch 00374: val_loss did not improve from 0.10000\n","\n","Epoch 00375: val_loss did not improve from 0.10000\n","\n","Epoch 00376: val_loss did not improve from 0.10000\n","\n","Epoch 00377: val_loss did not improve from 0.10000\n","\n","Epoch 00378: val_loss did not improve from 0.10000\n","\n","Epoch 00379: val_loss did not improve from 0.10000\n","\n","Epoch 00380: val_loss did not improve from 0.10000\n","\n","Epoch 00381: val_loss did not improve from 0.10000\n","\n","Epoch 00382: val_loss did not improve from 0.10000\n","\n","Epoch 00383: val_loss did not improve from 0.10000\n","\n","Epoch 00384: val_loss did not improve from 0.10000\n","\n","Epoch 00385: val_loss did not improve from 0.10000\n","\n","Epoch 00386: val_loss did not improve from 0.10000\n","\n","Epoch 00387: val_loss did not improve from 0.10000\n","\n","Epoch 00388: val_loss did not improve from 0.10000\n","\n","Epoch 00389: val_loss did not improve from 0.10000\n","\n","Epoch 00390: val_loss did not improve from 0.10000\n","\n","Epoch 00391: val_loss did not improve from 0.10000\n","\n","Epoch 00392: val_loss did not improve from 0.10000\n","\n","Epoch 00393: val_loss improved from 0.10000 to 0.09878, saving model to ./model/393-0.0988.hdf5\n","\n","Epoch 00394: val_loss did not improve from 0.09878\n","\n","Epoch 00395: val_loss did not improve from 0.09878\n","\n","Epoch 00396: val_loss did not improve from 0.09878\n","\n","Epoch 00397: val_loss improved from 0.09878 to 0.09796, saving model to ./model/397-0.0980.hdf5\n","\n","Epoch 00398: val_loss improved from 0.09796 to 0.09751, saving model to ./model/398-0.0975.hdf5\n","\n","Epoch 00399: val_loss did not improve from 0.09751\n","\n","Epoch 00400: val_loss did not improve from 0.09751\n","\n","Epoch 00401: val_loss did not improve from 0.09751\n","\n","Epoch 00402: val_loss improved from 0.09751 to 0.09666, saving model to ./model/402-0.0967.hdf5\n","\n","Epoch 00403: val_loss did not improve from 0.09666\n","\n","Epoch 00404: val_loss did not improve from 0.09666\n","\n","Epoch 00405: val_loss did not improve from 0.09666\n","\n","Epoch 00406: val_loss did not improve from 0.09666\n","\n","Epoch 00407: val_loss did not improve from 0.09666\n","\n","Epoch 00408: val_loss did not improve from 0.09666\n","\n","Epoch 00409: val_loss did not improve from 0.09666\n","\n","Epoch 00410: val_loss did not improve from 0.09666\n","\n","Epoch 00411: val_loss improved from 0.09666 to 0.09648, saving model to ./model/411-0.0965.hdf5\n","\n","Epoch 00412: val_loss did not improve from 0.09648\n","\n","Epoch 00413: val_loss did not improve from 0.09648\n","\n","Epoch 00414: val_loss did not improve from 0.09648\n","\n","Epoch 00415: val_loss did not improve from 0.09648\n","\n","Epoch 00416: val_loss did not improve from 0.09648\n","\n","Epoch 00417: val_loss did not improve from 0.09648\n","\n","Epoch 00418: val_loss did not improve from 0.09648\n","\n","Epoch 00419: val_loss improved from 0.09648 to 0.09539, saving model to ./model/419-0.0954.hdf5\n","\n","Epoch 00420: val_loss did not improve from 0.09539\n","\n","Epoch 00421: val_loss did not improve from 0.09539\n","\n","Epoch 00422: val_loss did not improve from 0.09539\n","\n","Epoch 00423: val_loss did not improve from 0.09539\n","\n","Epoch 00424: val_loss did not improve from 0.09539\n","\n","Epoch 00425: val_loss did not improve from 0.09539\n","\n","Epoch 00426: val_loss did not improve from 0.09539\n","\n","Epoch 00427: val_loss improved from 0.09539 to 0.09525, saving model to ./model/427-0.0953.hdf5\n","\n","Epoch 00428: val_loss did not improve from 0.09525\n","\n","Epoch 00429: val_loss did not improve from 0.09525\n","\n","Epoch 00430: val_loss did not improve from 0.09525\n","\n","Epoch 00431: val_loss did not improve from 0.09525\n","\n","Epoch 00432: val_loss did not improve from 0.09525\n","\n","Epoch 00433: val_loss did not improve from 0.09525\n","\n","Epoch 00434: val_loss improved from 0.09525 to 0.09503, saving model to ./model/434-0.0950.hdf5\n","\n","Epoch 00435: val_loss improved from 0.09503 to 0.09482, saving model to ./model/435-0.0948.hdf5\n","\n","Epoch 00436: val_loss did not improve from 0.09482\n","\n","Epoch 00437: val_loss did not improve from 0.09482\n","\n","Epoch 00438: val_loss did not improve from 0.09482\n","\n","Epoch 00439: val_loss improved from 0.09482 to 0.09384, saving model to ./model/439-0.0938.hdf5\n","\n","Epoch 00440: val_loss did not improve from 0.09384\n","\n","Epoch 00441: val_loss did not improve from 0.09384\n","\n","Epoch 00442: val_loss improved from 0.09384 to 0.09356, saving model to ./model/442-0.0936.hdf5\n","\n","Epoch 00443: val_loss did not improve from 0.09356\n","\n","Epoch 00444: val_loss did not improve from 0.09356\n","\n","Epoch 00445: val_loss did not improve from 0.09356\n","\n","Epoch 00446: val_loss did not improve from 0.09356\n","\n","Epoch 00447: val_loss did not improve from 0.09356\n","\n","Epoch 00448: val_loss did not improve from 0.09356\n","\n","Epoch 00449: val_loss did not improve from 0.09356\n","\n","Epoch 00450: val_loss did not improve from 0.09356\n","\n","Epoch 00451: val_loss did not improve from 0.09356\n","\n","Epoch 00452: val_loss did not improve from 0.09356\n","\n","Epoch 00453: val_loss did not improve from 0.09356\n","\n","Epoch 00454: val_loss improved from 0.09356 to 0.09315, saving model to ./model/454-0.0932.hdf5\n","\n","Epoch 00455: val_loss did not improve from 0.09315\n","\n","Epoch 00456: val_loss did not improve from 0.09315\n","\n","Epoch 00457: val_loss did not improve from 0.09315\n","\n","Epoch 00458: val_loss did not improve from 0.09315\n","\n","Epoch 00459: val_loss did not improve from 0.09315\n","\n","Epoch 00460: val_loss did not improve from 0.09315\n","\n","Epoch 00461: val_loss did not improve from 0.09315\n","\n","Epoch 00462: val_loss did not improve from 0.09315\n","\n","Epoch 00463: val_loss did not improve from 0.09315\n","\n","Epoch 00464: val_loss did not improve from 0.09315\n","\n","Epoch 00465: val_loss improved from 0.09315 to 0.09187, saving model to ./model/465-0.0919.hdf5\n","\n","Epoch 00466: val_loss did not improve from 0.09187\n","\n","Epoch 00467: val_loss did not improve from 0.09187\n","\n","Epoch 00468: val_loss did not improve from 0.09187\n","\n","Epoch 00469: val_loss improved from 0.09187 to 0.09115, saving model to ./model/469-0.0911.hdf5\n","\n","Epoch 00470: val_loss did not improve from 0.09115\n","\n","Epoch 00471: val_loss did not improve from 0.09115\n","\n","Epoch 00472: val_loss improved from 0.09115 to 0.09073, saving model to ./model/472-0.0907.hdf5\n","\n","Epoch 00473: val_loss improved from 0.09073 to 0.08978, saving model to ./model/473-0.0898.hdf5\n","\n","Epoch 00474: val_loss did not improve from 0.08978\n","\n","Epoch 00475: val_loss did not improve from 0.08978\n","\n","Epoch 00476: val_loss did not improve from 0.08978\n","\n","Epoch 00477: val_loss did not improve from 0.08978\n","\n","Epoch 00478: val_loss did not improve from 0.08978\n","\n","Epoch 00479: val_loss did not improve from 0.08978\n","\n","Epoch 00480: val_loss did not improve from 0.08978\n","\n","Epoch 00481: val_loss did not improve from 0.08978\n","\n","Epoch 00482: val_loss did not improve from 0.08978\n","\n","Epoch 00483: val_loss did not improve from 0.08978\n","\n","Epoch 00484: val_loss did not improve from 0.08978\n","\n","Epoch 00485: val_loss improved from 0.08978 to 0.08958, saving model to ./model/485-0.0896.hdf5\n","\n","Epoch 00486: val_loss did not improve from 0.08958\n","\n","Epoch 00487: val_loss did not improve from 0.08958\n","\n","Epoch 00488: val_loss did not improve from 0.08958\n","\n","Epoch 00489: val_loss did not improve from 0.08958\n","\n","Epoch 00490: val_loss improved from 0.08958 to 0.08932, saving model to ./model/490-0.0893.hdf5\n","\n","Epoch 00491: val_loss did not improve from 0.08932\n","\n","Epoch 00492: val_loss did not improve from 0.08932\n","\n","Epoch 00493: val_loss did not improve from 0.08932\n","\n","Epoch 00494: val_loss did not improve from 0.08932\n","\n","Epoch 00495: val_loss did not improve from 0.08932\n","\n","Epoch 00496: val_loss improved from 0.08932 to 0.08914, saving model to ./model/496-0.0891.hdf5\n","\n","Epoch 00497: val_loss improved from 0.08914 to 0.08827, saving model to ./model/497-0.0883.hdf5\n","\n","Epoch 00498: val_loss did not improve from 0.08827\n","\n","Epoch 00499: val_loss did not improve from 0.08827\n","\n","Epoch 00500: val_loss did not improve from 0.08827\n","\n","Epoch 00501: val_loss improved from 0.08827 to 0.08696, saving model to ./model/501-0.0870.hdf5\n","\n","Epoch 00502: val_loss did not improve from 0.08696\n","\n","Epoch 00503: val_loss did not improve from 0.08696\n","\n","Epoch 00504: val_loss improved from 0.08696 to 0.08694, saving model to ./model/504-0.0869.hdf5\n","\n","Epoch 00505: val_loss improved from 0.08694 to 0.08652, saving model to ./model/505-0.0865.hdf5\n","\n","Epoch 00506: val_loss did not improve from 0.08652\n","\n","Epoch 00507: val_loss did not improve from 0.08652\n","\n","Epoch 00508: val_loss did not improve from 0.08652\n","\n","Epoch 00509: val_loss did not improve from 0.08652\n","\n","Epoch 00510: val_loss did not improve from 0.08652\n","\n","Epoch 00511: val_loss did not improve from 0.08652\n","\n","Epoch 00512: val_loss did not improve from 0.08652\n","\n","Epoch 00513: val_loss did not improve from 0.08652\n","\n","Epoch 00514: val_loss did not improve from 0.08652\n","\n","Epoch 00515: val_loss did not improve from 0.08652\n","\n","Epoch 00516: val_loss did not improve from 0.08652\n","\n","Epoch 00517: val_loss did not improve from 0.08652\n","\n","Epoch 00518: val_loss did not improve from 0.08652\n","\n","Epoch 00519: val_loss did not improve from 0.08652\n","\n","Epoch 00520: val_loss did not improve from 0.08652\n","\n","Epoch 00521: val_loss did not improve from 0.08652\n","\n","Epoch 00522: val_loss did not improve from 0.08652\n","\n","Epoch 00523: val_loss did not improve from 0.08652\n","\n","Epoch 00524: val_loss did not improve from 0.08652\n","\n","Epoch 00525: val_loss did not improve from 0.08652\n","\n","Epoch 00526: val_loss did not improve from 0.08652\n","\n","Epoch 00527: val_loss did not improve from 0.08652\n","\n","Epoch 00528: val_loss did not improve from 0.08652\n","\n","Epoch 00529: val_loss improved from 0.08652 to 0.08631, saving model to ./model/529-0.0863.hdf5\n","\n","Epoch 00530: val_loss did not improve from 0.08631\n","\n","Epoch 00531: val_loss did not improve from 0.08631\n","\n","Epoch 00532: val_loss did not improve from 0.08631\n","\n","Epoch 00533: val_loss did not improve from 0.08631\n","\n","Epoch 00534: val_loss did not improve from 0.08631\n","\n","Epoch 00535: val_loss did not improve from 0.08631\n","\n","Epoch 00536: val_loss improved from 0.08631 to 0.08616, saving model to ./model/536-0.0862.hdf5\n","\n","Epoch 00537: val_loss did not improve from 0.08616\n","\n","Epoch 00538: val_loss did not improve from 0.08616\n","\n","Epoch 00539: val_loss did not improve from 0.08616\n","\n","Epoch 00540: val_loss did not improve from 0.08616\n","\n","Epoch 00541: val_loss improved from 0.08616 to 0.08575, saving model to ./model/541-0.0858.hdf5\n","\n","Epoch 00542: val_loss did not improve from 0.08575\n","\n","Epoch 00543: val_loss did not improve from 0.08575\n","\n","Epoch 00544: val_loss did not improve from 0.08575\n","\n","Epoch 00545: val_loss improved from 0.08575 to 0.08568, saving model to ./model/545-0.0857.hdf5\n","\n","Epoch 00546: val_loss did not improve from 0.08568\n","\n","Epoch 00547: val_loss did not improve from 0.08568\n","\n","Epoch 00548: val_loss did not improve from 0.08568\n","\n","Epoch 00549: val_loss did not improve from 0.08568\n","\n","Epoch 00550: val_loss did not improve from 0.08568\n","\n","Epoch 00551: val_loss did not improve from 0.08568\n","\n","Epoch 00552: val_loss did not improve from 0.08568\n","\n","Epoch 00553: val_loss improved from 0.08568 to 0.08519, saving model to ./model/553-0.0852.hdf5\n","\n","Epoch 00554: val_loss did not improve from 0.08519\n","\n","Epoch 00555: val_loss did not improve from 0.08519\n","\n","Epoch 00556: val_loss did not improve from 0.08519\n","\n","Epoch 00557: val_loss did not improve from 0.08519\n","\n","Epoch 00558: val_loss did not improve from 0.08519\n","\n","Epoch 00559: val_loss did not improve from 0.08519\n","\n","Epoch 00560: val_loss improved from 0.08519 to 0.08298, saving model to ./model/560-0.0830.hdf5\n","\n","Epoch 00561: val_loss did not improve from 0.08298\n","\n","Epoch 00562: val_loss did not improve from 0.08298\n","\n","Epoch 00563: val_loss did not improve from 0.08298\n","\n","Epoch 00564: val_loss improved from 0.08298 to 0.08256, saving model to ./model/564-0.0826.hdf5\n","\n","Epoch 00565: val_loss improved from 0.08256 to 0.08245, saving model to ./model/565-0.0825.hdf5\n","\n","Epoch 00566: val_loss did not improve from 0.08245\n","\n","Epoch 00567: val_loss did not improve from 0.08245\n","\n","Epoch 00568: val_loss did not improve from 0.08245\n","\n","Epoch 00569: val_loss did not improve from 0.08245\n","\n","Epoch 00570: val_loss did not improve from 0.08245\n","\n","Epoch 00571: val_loss did not improve from 0.08245\n","\n","Epoch 00572: val_loss did not improve from 0.08245\n","\n","Epoch 00573: val_loss did not improve from 0.08245\n","\n","Epoch 00574: val_loss did not improve from 0.08245\n","\n","Epoch 00575: val_loss did not improve from 0.08245\n","\n","Epoch 00576: val_loss did not improve from 0.08245\n","\n","Epoch 00577: val_loss did not improve from 0.08245\n","\n","Epoch 00578: val_loss did not improve from 0.08245\n","\n","Epoch 00579: val_loss did not improve from 0.08245\n","\n","Epoch 00580: val_loss did not improve from 0.08245\n","\n","Epoch 00581: val_loss did not improve from 0.08245\n","\n","Epoch 00582: val_loss did not improve from 0.08245\n","\n","Epoch 00583: val_loss did not improve from 0.08245\n","\n","Epoch 00584: val_loss did not improve from 0.08245\n","\n","Epoch 00585: val_loss did not improve from 0.08245\n","\n","Epoch 00586: val_loss did not improve from 0.08245\n","\n","Epoch 00587: val_loss did not improve from 0.08245\n","\n","Epoch 00588: val_loss did not improve from 0.08245\n","\n","Epoch 00589: val_loss did not improve from 0.08245\n","\n","Epoch 00590: val_loss did not improve from 0.08245\n","\n","Epoch 00591: val_loss did not improve from 0.08245\n","\n","Epoch 00592: val_loss did not improve from 0.08245\n","\n","Epoch 00593: val_loss did not improve from 0.08245\n","\n","Epoch 00594: val_loss improved from 0.08245 to 0.08219, saving model to ./model/594-0.0822.hdf5\n","\n","Epoch 00595: val_loss did not improve from 0.08219\n","\n","Epoch 00596: val_loss did not improve from 0.08219\n","\n","Epoch 00597: val_loss did not improve from 0.08219\n","\n","Epoch 00598: val_loss improved from 0.08219 to 0.08124, saving model to ./model/598-0.0812.hdf5\n","\n","Epoch 00599: val_loss improved from 0.08124 to 0.08122, saving model to ./model/599-0.0812.hdf5\n","\n","Epoch 00600: val_loss did not improve from 0.08122\n","\n","Epoch 00601: val_loss did not improve from 0.08122\n","\n","Epoch 00602: val_loss did not improve from 0.08122\n","\n","Epoch 00603: val_loss did not improve from 0.08122\n","\n","Epoch 00604: val_loss did not improve from 0.08122\n","\n","Epoch 00605: val_loss did not improve from 0.08122\n","\n","Epoch 00606: val_loss did not improve from 0.08122\n","\n","Epoch 00607: val_loss improved from 0.08122 to 0.08090, saving model to ./model/607-0.0809.hdf5\n","\n","Epoch 00608: val_loss did not improve from 0.08090\n","\n","Epoch 00609: val_loss did not improve from 0.08090\n","\n","Epoch 00610: val_loss did not improve from 0.08090\n","\n","Epoch 00611: val_loss did not improve from 0.08090\n","\n","Epoch 00612: val_loss did not improve from 0.08090\n","\n","Epoch 00613: val_loss did not improve from 0.08090\n","\n","Epoch 00614: val_loss did not improve from 0.08090\n","\n","Epoch 00615: val_loss did not improve from 0.08090\n","\n","Epoch 00616: val_loss improved from 0.08090 to 0.08003, saving model to ./model/616-0.0800.hdf5\n","\n","Epoch 00617: val_loss did not improve from 0.08003\n","\n","Epoch 00618: val_loss did not improve from 0.08003\n","\n","Epoch 00619: val_loss did not improve from 0.08003\n","\n","Epoch 00620: val_loss did not improve from 0.08003\n","\n","Epoch 00621: val_loss did not improve from 0.08003\n","\n","Epoch 00622: val_loss did not improve from 0.08003\n","\n","Epoch 00623: val_loss did not improve from 0.08003\n","\n","Epoch 00624: val_loss did not improve from 0.08003\n","\n","Epoch 00625: val_loss improved from 0.08003 to 0.07970, saving model to ./model/625-0.0797.hdf5\n","\n","Epoch 00626: val_loss did not improve from 0.07970\n","\n","Epoch 00627: val_loss did not improve from 0.07970\n","\n","Epoch 00628: val_loss did not improve from 0.07970\n","\n","Epoch 00629: val_loss did not improve from 0.07970\n","\n","Epoch 00630: val_loss did not improve from 0.07970\n","\n","Epoch 00631: val_loss did not improve from 0.07970\n","\n","Epoch 00632: val_loss did not improve from 0.07970\n","\n","Epoch 00633: val_loss improved from 0.07970 to 0.07962, saving model to ./model/633-0.0796.hdf5\n","\n","Epoch 00634: val_loss did not improve from 0.07962\n","\n","Epoch 00635: val_loss did not improve from 0.07962\n","\n","Epoch 00636: val_loss did not improve from 0.07962\n","\n","Epoch 00637: val_loss improved from 0.07962 to 0.07873, saving model to ./model/637-0.0787.hdf5\n","\n","Epoch 00638: val_loss did not improve from 0.07873\n","\n","Epoch 00639: val_loss did not improve from 0.07873\n","\n","Epoch 00640: val_loss did not improve from 0.07873\n","\n","Epoch 00641: val_loss did not improve from 0.07873\n","\n","Epoch 00642: val_loss did not improve from 0.07873\n","\n","Epoch 00643: val_loss did not improve from 0.07873\n","\n","Epoch 00644: val_loss did not improve from 0.07873\n","\n","Epoch 00645: val_loss did not improve from 0.07873\n","\n","Epoch 00646: val_loss did not improve from 0.07873\n","\n","Epoch 00647: val_loss did not improve from 0.07873\n","\n","Epoch 00648: val_loss did not improve from 0.07873\n","\n","Epoch 00649: val_loss did not improve from 0.07873\n","\n","Epoch 00650: val_loss did not improve from 0.07873\n","\n","Epoch 00651: val_loss did not improve from 0.07873\n","\n","Epoch 00652: val_loss did not improve from 0.07873\n","\n","Epoch 00653: val_loss did not improve from 0.07873\n","\n","Epoch 00654: val_loss did not improve from 0.07873\n","\n","Epoch 00655: val_loss did not improve from 0.07873\n","\n","Epoch 00656: val_loss did not improve from 0.07873\n","\n","Epoch 00657: val_loss did not improve from 0.07873\n","\n","Epoch 00658: val_loss did not improve from 0.07873\n","\n","Epoch 00659: val_loss did not improve from 0.07873\n","\n","Epoch 00660: val_loss did not improve from 0.07873\n","\n","Epoch 00661: val_loss did not improve from 0.07873\n","\n","Epoch 00662: val_loss did not improve from 0.07873\n","\n","Epoch 00663: val_loss did not improve from 0.07873\n","\n","Epoch 00664: val_loss did not improve from 0.07873\n","\n","Epoch 00665: val_loss did not improve from 0.07873\n","\n","Epoch 00666: val_loss did not improve from 0.07873\n","\n","Epoch 00667: val_loss did not improve from 0.07873\n","\n","Epoch 00668: val_loss did not improve from 0.07873\n","\n","Epoch 00669: val_loss did not improve from 0.07873\n","\n","Epoch 00670: val_loss did not improve from 0.07873\n","\n","Epoch 00671: val_loss improved from 0.07873 to 0.07862, saving model to ./model/671-0.0786.hdf5\n","\n","Epoch 00672: val_loss did not improve from 0.07862\n","\n","Epoch 00673: val_loss did not improve from 0.07862\n","\n","Epoch 00674: val_loss did not improve from 0.07862\n","\n","Epoch 00675: val_loss did not improve from 0.07862\n","\n","Epoch 00676: val_loss did not improve from 0.07862\n","\n","Epoch 00677: val_loss did not improve from 0.07862\n","\n","Epoch 00678: val_loss did not improve from 0.07862\n","\n","Epoch 00679: val_loss improved from 0.07862 to 0.07797, saving model to ./model/679-0.0780.hdf5\n","\n","Epoch 00680: val_loss did not improve from 0.07797\n","\n","Epoch 00681: val_loss did not improve from 0.07797\n","\n","Epoch 00682: val_loss did not improve from 0.07797\n","\n","Epoch 00683: val_loss improved from 0.07797 to 0.07781, saving model to ./model/683-0.0778.hdf5\n","\n","Epoch 00684: val_loss did not improve from 0.07781\n","\n","Epoch 00685: val_loss did not improve from 0.07781\n","\n","Epoch 00686: val_loss did not improve from 0.07781\n","\n","Epoch 00687: val_loss improved from 0.07781 to 0.07775, saving model to ./model/687-0.0777.hdf5\n","\n","Epoch 00688: val_loss did not improve from 0.07775\n","\n","Epoch 00689: val_loss did not improve from 0.07775\n","\n","Epoch 00690: val_loss did not improve from 0.07775\n","\n","Epoch 00691: val_loss did not improve from 0.07775\n","\n","Epoch 00692: val_loss did not improve from 0.07775\n","\n","Epoch 00693: val_loss did not improve from 0.07775\n","\n","Epoch 00694: val_loss did not improve from 0.07775\n","\n","Epoch 00695: val_loss did not improve from 0.07775\n","\n","Epoch 00696: val_loss did not improve from 0.07775\n","\n","Epoch 00697: val_loss did not improve from 0.07775\n","\n","Epoch 00698: val_loss did not improve from 0.07775\n","\n","Epoch 00699: val_loss improved from 0.07775 to 0.07703, saving model to ./model/699-0.0770.hdf5\n","\n","Epoch 00700: val_loss improved from 0.07703 to 0.07697, saving model to ./model/700-0.0770.hdf5\n","\n","Epoch 00701: val_loss did not improve from 0.07697\n","\n","Epoch 00702: val_loss did not improve from 0.07697\n","\n","Epoch 00703: val_loss did not improve from 0.07697\n","\n","Epoch 00704: val_loss did not improve from 0.07697\n","\n","Epoch 00705: val_loss did not improve from 0.07697\n","\n","Epoch 00706: val_loss did not improve from 0.07697\n","\n","Epoch 00707: val_loss improved from 0.07697 to 0.07596, saving model to ./model/707-0.0760.hdf5\n","\n","Epoch 00708: val_loss did not improve from 0.07596\n","\n","Epoch 00709: val_loss did not improve from 0.07596\n","\n","Epoch 00710: val_loss did not improve from 0.07596\n","\n","Epoch 00711: val_loss improved from 0.07596 to 0.07445, saving model to ./model/711-0.0744.hdf5\n","\n","Epoch 00712: val_loss improved from 0.07445 to 0.07441, saving model to ./model/712-0.0744.hdf5\n","\n","Epoch 00713: val_loss did not improve from 0.07441\n","\n","Epoch 00714: val_loss did not improve from 0.07441\n","\n","Epoch 00715: val_loss did not improve from 0.07441\n","\n","Epoch 00716: val_loss did not improve from 0.07441\n","\n","Epoch 00717: val_loss did not improve from 0.07441\n","\n","Epoch 00718: val_loss did not improve from 0.07441\n","\n","Epoch 00719: val_loss did not improve from 0.07441\n","\n","Epoch 00720: val_loss did not improve from 0.07441\n","\n","Epoch 00721: val_loss did not improve from 0.07441\n","\n","Epoch 00722: val_loss did not improve from 0.07441\n","\n","Epoch 00723: val_loss did not improve from 0.07441\n","\n","Epoch 00724: val_loss did not improve from 0.07441\n","\n","Epoch 00725: val_loss did not improve from 0.07441\n","\n","Epoch 00726: val_loss did not improve from 0.07441\n","\n","Epoch 00727: val_loss improved from 0.07441 to 0.07425, saving model to ./model/727-0.0742.hdf5\n","\n","Epoch 00728: val_loss did not improve from 0.07425\n","\n","Epoch 00729: val_loss did not improve from 0.07425\n","\n","Epoch 00730: val_loss did not improve from 0.07425\n","\n","Epoch 00731: val_loss improved from 0.07425 to 0.07361, saving model to ./model/731-0.0736.hdf5\n","\n","Epoch 00732: val_loss did not improve from 0.07361\n","\n","Epoch 00733: val_loss did not improve from 0.07361\n","\n","Epoch 00734: val_loss did not improve from 0.07361\n","\n","Epoch 00735: val_loss did not improve from 0.07361\n","\n","Epoch 00736: val_loss did not improve from 0.07361\n","\n","Epoch 00737: val_loss did not improve from 0.07361\n","\n","Epoch 00738: val_loss did not improve from 0.07361\n","\n","Epoch 00739: val_loss did not improve from 0.07361\n","\n","Epoch 00740: val_loss did not improve from 0.07361\n","\n","Epoch 00741: val_loss did not improve from 0.07361\n","\n","Epoch 00742: val_loss improved from 0.07361 to 0.07310, saving model to ./model/742-0.0731.hdf5\n","\n","Epoch 00743: val_loss improved from 0.07310 to 0.07249, saving model to ./model/743-0.0725.hdf5\n","\n","Epoch 00744: val_loss did not improve from 0.07249\n","\n","Epoch 00745: val_loss did not improve from 0.07249\n","\n","Epoch 00746: val_loss improved from 0.07249 to 0.07190, saving model to ./model/746-0.0719.hdf5\n","\n","Epoch 00747: val_loss did not improve from 0.07190\n","\n","Epoch 00748: val_loss did not improve from 0.07190\n","\n","Epoch 00749: val_loss did not improve from 0.07190\n","\n","Epoch 00750: val_loss did not improve from 0.07190\n","\n","Epoch 00751: val_loss improved from 0.07190 to 0.07150, saving model to ./model/751-0.0715.hdf5\n","\n","Epoch 00752: val_loss did not improve from 0.07150\n","\n","Epoch 00753: val_loss did not improve from 0.07150\n","\n","Epoch 00754: val_loss did not improve from 0.07150\n","\n","Epoch 00755: val_loss did not improve from 0.07150\n","\n","Epoch 00756: val_loss did not improve from 0.07150\n","\n","Epoch 00757: val_loss did not improve from 0.07150\n","\n","Epoch 00758: val_loss did not improve from 0.07150\n","\n","Epoch 00759: val_loss did not improve from 0.07150\n","\n","Epoch 00760: val_loss did not improve from 0.07150\n","\n","Epoch 00761: val_loss did not improve from 0.07150\n","\n","Epoch 00762: val_loss did not improve from 0.07150\n","\n","Epoch 00763: val_loss improved from 0.07150 to 0.07124, saving model to ./model/763-0.0712.hdf5\n","\n","Epoch 00764: val_loss did not improve from 0.07124\n","\n","Epoch 00765: val_loss did not improve from 0.07124\n","\n","Epoch 00766: val_loss did not improve from 0.07124\n","\n","Epoch 00767: val_loss did not improve from 0.07124\n","\n","Epoch 00768: val_loss did not improve from 0.07124\n","\n","Epoch 00769: val_loss did not improve from 0.07124\n","\n","Epoch 00770: val_loss did not improve from 0.07124\n","\n","Epoch 00771: val_loss did not improve from 0.07124\n","\n","Epoch 00772: val_loss did not improve from 0.07124\n","\n","Epoch 00773: val_loss did not improve from 0.07124\n","\n","Epoch 00774: val_loss did not improve from 0.07124\n","\n","Epoch 00775: val_loss did not improve from 0.07124\n","\n","Epoch 00776: val_loss did not improve from 0.07124\n","\n","Epoch 00777: val_loss did not improve from 0.07124\n","\n","Epoch 00778: val_loss did not improve from 0.07124\n","\n","Epoch 00779: val_loss did not improve from 0.07124\n","\n","Epoch 00780: val_loss did not improve from 0.07124\n","\n","Epoch 00781: val_loss did not improve from 0.07124\n","\n","Epoch 00782: val_loss did not improve from 0.07124\n","\n","Epoch 00783: val_loss did not improve from 0.07124\n","\n","Epoch 00784: val_loss did not improve from 0.07124\n","\n","Epoch 00785: val_loss improved from 0.07124 to 0.07123, saving model to ./model/785-0.0712.hdf5\n","\n","Epoch 00786: val_loss improved from 0.07123 to 0.07098, saving model to ./model/786-0.0710.hdf5\n","\n","Epoch 00787: val_loss did not improve from 0.07098\n","\n","Epoch 00788: val_loss did not improve from 0.07098\n","\n","Epoch 00789: val_loss did not improve from 0.07098\n","\n","Epoch 00790: val_loss did not improve from 0.07098\n","\n","Epoch 00791: val_loss improved from 0.07098 to 0.07076, saving model to ./model/791-0.0708.hdf5\n","\n","Epoch 00792: val_loss did not improve from 0.07076\n","\n","Epoch 00793: val_loss did not improve from 0.07076\n","\n","Epoch 00794: val_loss did not improve from 0.07076\n","\n","Epoch 00795: val_loss did not improve from 0.07076\n","\n","Epoch 00796: val_loss improved from 0.07076 to 0.07064, saving model to ./model/796-0.0706.hdf5\n","\n","Epoch 00797: val_loss did not improve from 0.07064\n","\n","Epoch 00798: val_loss did not improve from 0.07064\n","\n","Epoch 00799: val_loss did not improve from 0.07064\n","\n","Epoch 00800: val_loss did not improve from 0.07064\n","\n","Epoch 00801: val_loss did not improve from 0.07064\n","\n","Epoch 00802: val_loss did not improve from 0.07064\n","\n","Epoch 00803: val_loss did not improve from 0.07064\n","\n","Epoch 00804: val_loss did not improve from 0.07064\n","\n","Epoch 00805: val_loss did not improve from 0.07064\n","\n","Epoch 00806: val_loss did not improve from 0.07064\n","\n","Epoch 00807: val_loss improved from 0.07064 to 0.07022, saving model to ./model/807-0.0702.hdf5\n","\n","Epoch 00808: val_loss did not improve from 0.07022\n","\n","Epoch 00809: val_loss did not improve from 0.07022\n","\n","Epoch 00810: val_loss did not improve from 0.07022\n","\n","Epoch 00811: val_loss did not improve from 0.07022\n","\n","Epoch 00812: val_loss did not improve from 0.07022\n","\n","Epoch 00813: val_loss did not improve from 0.07022\n","\n","Epoch 00814: val_loss did not improve from 0.07022\n","\n","Epoch 00815: val_loss did not improve from 0.07022\n","\n","Epoch 00816: val_loss improved from 0.07022 to 0.07021, saving model to ./model/816-0.0702.hdf5\n","\n","Epoch 00817: val_loss did not improve from 0.07021\n","\n","Epoch 00818: val_loss did not improve from 0.07021\n","\n","Epoch 00819: val_loss did not improve from 0.07021\n","\n","Epoch 00820: val_loss did not improve from 0.07021\n","\n","Epoch 00821: val_loss did not improve from 0.07021\n","\n","Epoch 00822: val_loss improved from 0.07021 to 0.06977, saving model to ./model/822-0.0698.hdf5\n","\n","Epoch 00823: val_loss did not improve from 0.06977\n","\n","Epoch 00824: val_loss did not improve from 0.06977\n","\n","Epoch 00825: val_loss did not improve from 0.06977\n","\n","Epoch 00826: val_loss improved from 0.06977 to 0.06961, saving model to ./model/826-0.0696.hdf5\n","\n","Epoch 00827: val_loss did not improve from 0.06961\n","\n","Epoch 00828: val_loss did not improve from 0.06961\n","\n","Epoch 00829: val_loss did not improve from 0.06961\n","\n","Epoch 00830: val_loss did not improve from 0.06961\n","\n","Epoch 00831: val_loss did not improve from 0.06961\n","\n","Epoch 00832: val_loss did not improve from 0.06961\n","\n","Epoch 00833: val_loss improved from 0.06961 to 0.06960, saving model to ./model/833-0.0696.hdf5\n","\n","Epoch 00834: val_loss did not improve from 0.06960\n","\n","Epoch 00835: val_loss did not improve from 0.06960\n","\n","Epoch 00836: val_loss did not improve from 0.06960\n","\n","Epoch 00837: val_loss did not improve from 0.06960\n","\n","Epoch 00838: val_loss did not improve from 0.06960\n","\n","Epoch 00839: val_loss did not improve from 0.06960\n","\n","Epoch 00840: val_loss did not improve from 0.06960\n","\n","Epoch 00841: val_loss did not improve from 0.06960\n","\n","Epoch 00842: val_loss improved from 0.06960 to 0.06843, saving model to ./model/842-0.0684.hdf5\n","\n","Epoch 00843: val_loss did not improve from 0.06843\n","\n","Epoch 00844: val_loss did not improve from 0.06843\n","\n","Epoch 00845: val_loss did not improve from 0.06843\n","\n","Epoch 00846: val_loss did not improve from 0.06843\n","\n","Epoch 00847: val_loss did not improve from 0.06843\n","\n","Epoch 00848: val_loss did not improve from 0.06843\n","\n","Epoch 00849: val_loss did not improve from 0.06843\n","\n","Epoch 00850: val_loss did not improve from 0.06843\n","\n","Epoch 00851: val_loss improved from 0.06843 to 0.06826, saving model to ./model/851-0.0683.hdf5\n","\n","Epoch 00852: val_loss did not improve from 0.06826\n","\n","Epoch 00853: val_loss did not improve from 0.06826\n","\n","Epoch 00854: val_loss improved from 0.06826 to 0.06778, saving model to ./model/854-0.0678.hdf5\n","\n","Epoch 00855: val_loss did not improve from 0.06778\n","\n","Epoch 00856: val_loss did not improve from 0.06778\n","\n","Epoch 00857: val_loss did not improve from 0.06778\n","\n","Epoch 00858: val_loss did not improve from 0.06778\n","\n","Epoch 00859: val_loss did not improve from 0.06778\n","\n","Epoch 00860: val_loss did not improve from 0.06778\n","\n","Epoch 00861: val_loss did not improve from 0.06778\n","\n","Epoch 00862: val_loss did not improve from 0.06778\n","\n","Epoch 00863: val_loss did not improve from 0.06778\n","\n","Epoch 00864: val_loss did not improve from 0.06778\n","\n","Epoch 00865: val_loss did not improve from 0.06778\n","\n","Epoch 00866: val_loss did not improve from 0.06778\n","\n","Epoch 00867: val_loss did not improve from 0.06778\n","\n","Epoch 00868: val_loss did not improve from 0.06778\n","\n","Epoch 00869: val_loss did not improve from 0.06778\n","\n","Epoch 00870: val_loss did not improve from 0.06778\n","\n","Epoch 00871: val_loss did not improve from 0.06778\n","\n","Epoch 00872: val_loss did not improve from 0.06778\n","\n","Epoch 00873: val_loss did not improve from 0.06778\n","\n","Epoch 00874: val_loss did not improve from 0.06778\n","\n","Epoch 00875: val_loss did not improve from 0.06778\n","\n","Epoch 00876: val_loss did not improve from 0.06778\n","\n","Epoch 00877: val_loss did not improve from 0.06778\n","\n","Epoch 00878: val_loss did not improve from 0.06778\n","\n","Epoch 00879: val_loss did not improve from 0.06778\n","\n","Epoch 00880: val_loss did not improve from 0.06778\n","\n","Epoch 00881: val_loss did not improve from 0.06778\n","\n","Epoch 00882: val_loss did not improve from 0.06778\n","\n","Epoch 00883: val_loss improved from 0.06778 to 0.06778, saving model to ./model/883-0.0678.hdf5\n","\n","Epoch 00884: val_loss did not improve from 0.06778\n","\n","Epoch 00885: val_loss did not improve from 0.06778\n","\n","Epoch 00886: val_loss did not improve from 0.06778\n","\n","Epoch 00887: val_loss improved from 0.06778 to 0.06742, saving model to ./model/887-0.0674.hdf5\n","\n","Epoch 00888: val_loss did not improve from 0.06742\n","\n","Epoch 00889: val_loss did not improve from 0.06742\n","\n","Epoch 00890: val_loss did not improve from 0.06742\n","\n","Epoch 00891: val_loss improved from 0.06742 to 0.06668, saving model to ./model/891-0.0667.hdf5\n","\n","Epoch 00892: val_loss improved from 0.06668 to 0.06597, saving model to ./model/892-0.0660.hdf5\n","\n","Epoch 00893: val_loss did not improve from 0.06597\n","\n","Epoch 00894: val_loss did not improve from 0.06597\n","\n","Epoch 00895: val_loss did not improve from 0.06597\n","\n","Epoch 00896: val_loss did not improve from 0.06597\n","\n","Epoch 00897: val_loss did not improve from 0.06597\n","\n","Epoch 00898: val_loss did not improve from 0.06597\n","\n","Epoch 00899: val_loss did not improve from 0.06597\n","\n","Epoch 00900: val_loss did not improve from 0.06597\n","\n","Epoch 00901: val_loss did not improve from 0.06597\n","\n","Epoch 00902: val_loss did not improve from 0.06597\n","\n","Epoch 00903: val_loss did not improve from 0.06597\n","\n","Epoch 00904: val_loss did not improve from 0.06597\n","\n","Epoch 00905: val_loss did not improve from 0.06597\n","\n","Epoch 00906: val_loss did not improve from 0.06597\n","\n","Epoch 00907: val_loss did not improve from 0.06597\n","\n","Epoch 00908: val_loss did not improve from 0.06597\n","\n","Epoch 00909: val_loss did not improve from 0.06597\n","\n","Epoch 00910: val_loss did not improve from 0.06597\n","\n","Epoch 00911: val_loss did not improve from 0.06597\n","\n","Epoch 00912: val_loss did not improve from 0.06597\n","\n","Epoch 00913: val_loss did not improve from 0.06597\n","\n","Epoch 00914: val_loss did not improve from 0.06597\n","\n","Epoch 00915: val_loss did not improve from 0.06597\n","\n","Epoch 00916: val_loss did not improve from 0.06597\n","\n","Epoch 00917: val_loss did not improve from 0.06597\n","\n","Epoch 00918: val_loss did not improve from 0.06597\n","\n","Epoch 00919: val_loss did not improve from 0.06597\n","\n","Epoch 00920: val_loss did not improve from 0.06597\n","\n","Epoch 00921: val_loss did not improve from 0.06597\n","\n","Epoch 00922: val_loss did not improve from 0.06597\n","\n","Epoch 00923: val_loss did not improve from 0.06597\n","\n","Epoch 00924: val_loss did not improve from 0.06597\n","\n","Epoch 00925: val_loss did not improve from 0.06597\n","\n","Epoch 00926: val_loss did not improve from 0.06597\n","\n","Epoch 00927: val_loss did not improve from 0.06597\n","\n","Epoch 00928: val_loss did not improve from 0.06597\n","\n","Epoch 00929: val_loss did not improve from 0.06597\n","\n","Epoch 00930: val_loss did not improve from 0.06597\n","\n","Epoch 00931: val_loss did not improve from 0.06597\n","\n","Epoch 00932: val_loss did not improve from 0.06597\n","\n","Epoch 00933: val_loss did not improve from 0.06597\n","\n","Epoch 00934: val_loss did not improve from 0.06597\n","\n","Epoch 00935: val_loss did not improve from 0.06597\n","\n","Epoch 00936: val_loss did not improve from 0.06597\n","\n","Epoch 00937: val_loss did not improve from 0.06597\n","\n","Epoch 00938: val_loss did not improve from 0.06597\n","\n","Epoch 00939: val_loss did not improve from 0.06597\n","\n","Epoch 00940: val_loss did not improve from 0.06597\n","\n","Epoch 00941: val_loss did not improve from 0.06597\n","\n","Epoch 00942: val_loss did not improve from 0.06597\n","\n","Epoch 00943: val_loss improved from 0.06597 to 0.06491, saving model to ./model/943-0.0649.hdf5\n","\n","Epoch 00944: val_loss did not improve from 0.06491\n","\n","Epoch 00945: val_loss did not improve from 0.06491\n","\n","Epoch 00946: val_loss did not improve from 0.06491\n","\n","Epoch 00947: val_loss did not improve from 0.06491\n","\n","Epoch 00948: val_loss did not improve from 0.06491\n","\n","Epoch 00949: val_loss did not improve from 0.06491\n","\n","Epoch 00950: val_loss did not improve from 0.06491\n","\n","Epoch 00951: val_loss improved from 0.06491 to 0.06490, saving model to ./model/951-0.0649.hdf5\n","\n","Epoch 00952: val_loss did not improve from 0.06490\n","\n","Epoch 00953: val_loss did not improve from 0.06490\n","\n","Epoch 00954: val_loss improved from 0.06490 to 0.06488, saving model to ./model/954-0.0649.hdf5\n","\n","Epoch 00955: val_loss did not improve from 0.06488\n","\n","Epoch 00956: val_loss did not improve from 0.06488\n","\n","Epoch 00957: val_loss did not improve from 0.06488\n","\n","Epoch 00958: val_loss did not improve from 0.06488\n","\n","Epoch 00959: val_loss improved from 0.06488 to 0.06355, saving model to ./model/959-0.0636.hdf5\n","\n","Epoch 00960: val_loss did not improve from 0.06355\n","\n","Epoch 00961: val_loss did not improve from 0.06355\n","\n","Epoch 00962: val_loss did not improve from 0.06355\n","\n","Epoch 00963: val_loss did not improve from 0.06355\n","\n","Epoch 00964: val_loss did not improve from 0.06355\n","\n","Epoch 00965: val_loss did not improve from 0.06355\n","\n","Epoch 00966: val_loss did not improve from 0.06355\n","\n","Epoch 00967: val_loss did not improve from 0.06355\n","\n","Epoch 00968: val_loss did not improve from 0.06355\n","\n","Epoch 00969: val_loss did not improve from 0.06355\n","\n","Epoch 00970: val_loss did not improve from 0.06355\n","\n","Epoch 00971: val_loss did not improve from 0.06355\n","\n","Epoch 00972: val_loss did not improve from 0.06355\n","\n","Epoch 00973: val_loss did not improve from 0.06355\n","\n","Epoch 00974: val_loss did not improve from 0.06355\n","\n","Epoch 00975: val_loss did not improve from 0.06355\n","\n","Epoch 00976: val_loss did not improve from 0.06355\n","\n","Epoch 00977: val_loss did not improve from 0.06355\n","\n","Epoch 00978: val_loss did not improve from 0.06355\n","\n","Epoch 00979: val_loss did not improve from 0.06355\n","\n","Epoch 00980: val_loss did not improve from 0.06355\n","\n","Epoch 00981: val_loss did not improve from 0.06355\n","\n","Epoch 00982: val_loss did not improve from 0.06355\n","\n","Epoch 00983: val_loss improved from 0.06355 to 0.06313, saving model to ./model/983-0.0631.hdf5\n","\n","Epoch 00984: val_loss did not improve from 0.06313\n","\n","Epoch 00985: val_loss did not improve from 0.06313\n","\n","Epoch 00986: val_loss did not improve from 0.06313\n","\n","Epoch 00987: val_loss did not improve from 0.06313\n","\n","Epoch 00988: val_loss did not improve from 0.06313\n","\n","Epoch 00989: val_loss did not improve from 0.06313\n","\n","Epoch 00990: val_loss did not improve from 0.06313\n","\n","Epoch 00991: val_loss did not improve from 0.06313\n","\n","Epoch 00992: val_loss did not improve from 0.06313\n","\n","Epoch 00993: val_loss improved from 0.06313 to 0.06309, saving model to ./model/993-0.0631.hdf5\n","\n","Epoch 00994: val_loss improved from 0.06309 to 0.06252, saving model to ./model/994-0.0625.hdf5\n","\n","Epoch 00995: val_loss did not improve from 0.06252\n","\n","Epoch 00996: val_loss did not improve from 0.06252\n","\n","Epoch 00997: val_loss did not improve from 0.06252\n","\n","Epoch 00998: val_loss did not improve from 0.06252\n","\n","Epoch 00999: val_loss did not improve from 0.06252\n","\n","Epoch 01000: val_loss did not improve from 0.06252\n","\n","Epoch 01001: val_loss did not improve from 0.06252\n","\n","Epoch 01002: val_loss did not improve from 0.06252\n","\n","Epoch 01003: val_loss did not improve from 0.06252\n","\n","Epoch 01004: val_loss did not improve from 0.06252\n","\n","Epoch 01005: val_loss did not improve from 0.06252\n","\n","Epoch 01006: val_loss improved from 0.06252 to 0.06155, saving model to ./model/1006-0.0616.hdf5\n","\n","Epoch 01007: val_loss improved from 0.06155 to 0.06152, saving model to ./model/1007-0.0615.hdf5\n","\n","Epoch 01008: val_loss did not improve from 0.06152\n","\n","Epoch 01009: val_loss did not improve from 0.06152\n","\n","Epoch 01010: val_loss did not improve from 0.06152\n","\n","Epoch 01011: val_loss did not improve from 0.06152\n","\n","Epoch 01012: val_loss did not improve from 0.06152\n","\n","Epoch 01013: val_loss did not improve from 0.06152\n","\n","Epoch 01014: val_loss did not improve from 0.06152\n","\n","Epoch 01015: val_loss did not improve from 0.06152\n","\n","Epoch 01016: val_loss did not improve from 0.06152\n","\n","Epoch 01017: val_loss did not improve from 0.06152\n","\n","Epoch 01018: val_loss did not improve from 0.06152\n","\n","Epoch 01019: val_loss did not improve from 0.06152\n","\n","Epoch 01020: val_loss did not improve from 0.06152\n","\n","Epoch 01021: val_loss did not improve from 0.06152\n","\n","Epoch 01022: val_loss did not improve from 0.06152\n","\n","Epoch 01023: val_loss did not improve from 0.06152\n","\n","Epoch 01024: val_loss did not improve from 0.06152\n","\n","Epoch 01025: val_loss did not improve from 0.06152\n","\n","Epoch 01026: val_loss did not improve from 0.06152\n","\n","Epoch 01027: val_loss did not improve from 0.06152\n","\n","Epoch 01028: val_loss did not improve from 0.06152\n","\n","Epoch 01029: val_loss did not improve from 0.06152\n","\n","Epoch 01030: val_loss did not improve from 0.06152\n","\n","Epoch 01031: val_loss did not improve from 0.06152\n","\n","Epoch 01032: val_loss did not improve from 0.06152\n","\n","Epoch 01033: val_loss did not improve from 0.06152\n","\n","Epoch 01034: val_loss did not improve from 0.06152\n","\n","Epoch 01035: val_loss did not improve from 0.06152\n","\n","Epoch 01036: val_loss did not improve from 0.06152\n","\n","Epoch 01037: val_loss did not improve from 0.06152\n","\n","Epoch 01038: val_loss did not improve from 0.06152\n","\n","Epoch 01039: val_loss did not improve from 0.06152\n","\n","Epoch 01040: val_loss did not improve from 0.06152\n","\n","Epoch 01041: val_loss did not improve from 0.06152\n","\n","Epoch 01042: val_loss did not improve from 0.06152\n","\n","Epoch 01043: val_loss did not improve from 0.06152\n","\n","Epoch 01044: val_loss did not improve from 0.06152\n","\n","Epoch 01045: val_loss did not improve from 0.06152\n","\n","Epoch 01046: val_loss did not improve from 0.06152\n","\n","Epoch 01047: val_loss did not improve from 0.06152\n","\n","Epoch 01048: val_loss did not improve from 0.06152\n","\n","Epoch 01049: val_loss did not improve from 0.06152\n","\n","Epoch 01050: val_loss did not improve from 0.06152\n","\n","Epoch 01051: val_loss did not improve from 0.06152\n","\n","Epoch 01052: val_loss did not improve from 0.06152\n","\n","Epoch 01053: val_loss did not improve from 0.06152\n","\n","Epoch 01054: val_loss did not improve from 0.06152\n","\n","Epoch 01055: val_loss did not improve from 0.06152\n","\n","Epoch 01056: val_loss did not improve from 0.06152\n","\n","Epoch 01057: val_loss did not improve from 0.06152\n","\n","Epoch 01058: val_loss did not improve from 0.06152\n","\n","Epoch 01059: val_loss did not improve from 0.06152\n","\n","Epoch 01060: val_loss did not improve from 0.06152\n","\n","Epoch 01061: val_loss did not improve from 0.06152\n","\n","Epoch 01062: val_loss did not improve from 0.06152\n","\n","Epoch 01063: val_loss improved from 0.06152 to 0.06096, saving model to ./model/1063-0.0610.hdf5\n","\n","Epoch 01064: val_loss improved from 0.06096 to 0.06072, saving model to ./model/1064-0.0607.hdf5\n","\n","Epoch 01065: val_loss did not improve from 0.06072\n","\n","Epoch 01066: val_loss did not improve from 0.06072\n","\n","Epoch 01067: val_loss did not improve from 0.06072\n","\n","Epoch 01068: val_loss did not improve from 0.06072\n","\n","Epoch 01069: val_loss did not improve from 0.06072\n","\n","Epoch 01070: val_loss did not improve from 0.06072\n","\n","Epoch 01071: val_loss did not improve from 0.06072\n","\n","Epoch 01072: val_loss did not improve from 0.06072\n","\n","Epoch 01073: val_loss did not improve from 0.06072\n","\n","Epoch 01074: val_loss did not improve from 0.06072\n","\n","Epoch 01075: val_loss did not improve from 0.06072\n","\n","Epoch 01076: val_loss did not improve from 0.06072\n","\n","Epoch 01077: val_loss did not improve from 0.06072\n","\n","Epoch 01078: val_loss did not improve from 0.06072\n","\n","Epoch 01079: val_loss did not improve from 0.06072\n","\n","Epoch 01080: val_loss did not improve from 0.06072\n","\n","Epoch 01081: val_loss did not improve from 0.06072\n","\n","Epoch 01082: val_loss did not improve from 0.06072\n","\n","Epoch 01083: val_loss did not improve from 0.06072\n","\n","Epoch 01084: val_loss did not improve from 0.06072\n","\n","Epoch 01085: val_loss did not improve from 0.06072\n","\n","Epoch 01086: val_loss did not improve from 0.06072\n","\n","Epoch 01087: val_loss did not improve from 0.06072\n","\n","Epoch 01088: val_loss improved from 0.06072 to 0.06030, saving model to ./model/1088-0.0603.hdf5\n","\n","Epoch 01089: val_loss did not improve from 0.06030\n","\n","Epoch 01090: val_loss did not improve from 0.06030\n","\n","Epoch 01091: val_loss did not improve from 0.06030\n","\n","Epoch 01092: val_loss did not improve from 0.06030\n","\n","Epoch 01093: val_loss did not improve from 0.06030\n","\n","Epoch 01094: val_loss did not improve from 0.06030\n","\n","Epoch 01095: val_loss did not improve from 0.06030\n","\n","Epoch 01096: val_loss improved from 0.06030 to 0.06019, saving model to ./model/1096-0.0602.hdf5\n","\n","Epoch 01097: val_loss did not improve from 0.06019\n","\n","Epoch 01098: val_loss did not improve from 0.06019\n","\n","Epoch 01099: val_loss did not improve from 0.06019\n","\n","Epoch 01100: val_loss improved from 0.06019 to 0.05954, saving model to ./model/1100-0.0595.hdf5\n","\n","Epoch 01101: val_loss did not improve from 0.05954\n","\n","Epoch 01102: val_loss did not improve from 0.05954\n","\n","Epoch 01103: val_loss did not improve from 0.05954\n","\n","Epoch 01104: val_loss did not improve from 0.05954\n","\n","Epoch 01105: val_loss did not improve from 0.05954\n","\n","Epoch 01106: val_loss did not improve from 0.05954\n","\n","Epoch 01107: val_loss did not improve from 0.05954\n","\n","Epoch 01108: val_loss did not improve from 0.05954\n","\n","Epoch 01109: val_loss did not improve from 0.05954\n","\n","Epoch 01110: val_loss did not improve from 0.05954\n","\n","Epoch 01111: val_loss did not improve from 0.05954\n","\n","Epoch 01112: val_loss did not improve from 0.05954\n","\n","Epoch 01113: val_loss did not improve from 0.05954\n","\n","Epoch 01114: val_loss did not improve from 0.05954\n","\n","Epoch 01115: val_loss did not improve from 0.05954\n","\n","Epoch 01116: val_loss did not improve from 0.05954\n","\n","Epoch 01117: val_loss did not improve from 0.05954\n","\n","Epoch 01118: val_loss did not improve from 0.05954\n","\n","Epoch 01119: val_loss did not improve from 0.05954\n","\n","Epoch 01120: val_loss did not improve from 0.05954\n","\n","Epoch 01121: val_loss did not improve from 0.05954\n","\n","Epoch 01122: val_loss did not improve from 0.05954\n","\n","Epoch 01123: val_loss did not improve from 0.05954\n","\n","Epoch 01124: val_loss did not improve from 0.05954\n","\n","Epoch 01125: val_loss did not improve from 0.05954\n","\n","Epoch 01126: val_loss did not improve from 0.05954\n","\n","Epoch 01127: val_loss did not improve from 0.05954\n","\n","Epoch 01128: val_loss did not improve from 0.05954\n","\n","Epoch 01129: val_loss did not improve from 0.05954\n","\n","Epoch 01130: val_loss did not improve from 0.05954\n","\n","Epoch 01131: val_loss did not improve from 0.05954\n","\n","Epoch 01132: val_loss did not improve from 0.05954\n","\n","Epoch 01133: val_loss improved from 0.05954 to 0.05924, saving model to ./model/1133-0.0592.hdf5\n","\n","Epoch 01134: val_loss improved from 0.05924 to 0.05922, saving model to ./model/1134-0.0592.hdf5\n","\n","Epoch 01135: val_loss did not improve from 0.05922\n","\n","Epoch 01136: val_loss did not improve from 0.05922\n","\n","Epoch 01137: val_loss did not improve from 0.05922\n","\n","Epoch 01138: val_loss did not improve from 0.05922\n","\n","Epoch 01139: val_loss did not improve from 0.05922\n","\n","Epoch 01140: val_loss did not improve from 0.05922\n","\n","Epoch 01141: val_loss did not improve from 0.05922\n","\n","Epoch 01142: val_loss did not improve from 0.05922\n","\n","Epoch 01143: val_loss did not improve from 0.05922\n","\n","Epoch 01144: val_loss did not improve from 0.05922\n","\n","Epoch 01145: val_loss did not improve from 0.05922\n","\n","Epoch 01146: val_loss did not improve from 0.05922\n","\n","Epoch 01147: val_loss did not improve from 0.05922\n","\n","Epoch 01148: val_loss did not improve from 0.05922\n","\n","Epoch 01149: val_loss did not improve from 0.05922\n","\n","Epoch 01150: val_loss did not improve from 0.05922\n","\n","Epoch 01151: val_loss did not improve from 0.05922\n","\n","Epoch 01152: val_loss did not improve from 0.05922\n","\n","Epoch 01153: val_loss did not improve from 0.05922\n","\n","Epoch 01154: val_loss did not improve from 0.05922\n","\n","Epoch 01155: val_loss did not improve from 0.05922\n","\n","Epoch 01156: val_loss did not improve from 0.05922\n","\n","Epoch 01157: val_loss did not improve from 0.05922\n","\n","Epoch 01158: val_loss did not improve from 0.05922\n","\n","Epoch 01159: val_loss did not improve from 0.05922\n","\n","Epoch 01160: val_loss did not improve from 0.05922\n","\n","Epoch 01161: val_loss did not improve from 0.05922\n","\n","Epoch 01162: val_loss improved from 0.05922 to 0.05913, saving model to ./model/1162-0.0591.hdf5\n","\n","Epoch 01163: val_loss did not improve from 0.05913\n","\n","Epoch 01164: val_loss did not improve from 0.05913\n","\n","Epoch 01165: val_loss did not improve from 0.05913\n","\n","Epoch 01166: val_loss did not improve from 0.05913\n","\n","Epoch 01167: val_loss did not improve from 0.05913\n","\n","Epoch 01168: val_loss did not improve from 0.05913\n","\n","Epoch 01169: val_loss did not improve from 0.05913\n","\n","Epoch 01170: val_loss did not improve from 0.05913\n","\n","Epoch 01171: val_loss did not improve from 0.05913\n","\n","Epoch 01172: val_loss did not improve from 0.05913\n","\n","Epoch 01173: val_loss did not improve from 0.05913\n","\n","Epoch 01174: val_loss did not improve from 0.05913\n","\n","Epoch 01175: val_loss did not improve from 0.05913\n","\n","Epoch 01176: val_loss did not improve from 0.05913\n","\n","Epoch 01177: val_loss did not improve from 0.05913\n","\n","Epoch 01178: val_loss did not improve from 0.05913\n","\n","Epoch 01179: val_loss did not improve from 0.05913\n","\n","Epoch 01180: val_loss did not improve from 0.05913\n","\n","Epoch 01181: val_loss did not improve from 0.05913\n","\n","Epoch 01182: val_loss did not improve from 0.05913\n","\n","Epoch 01183: val_loss did not improve from 0.05913\n","\n","Epoch 01184: val_loss did not improve from 0.05913\n","\n","Epoch 01185: val_loss did not improve from 0.05913\n","\n","Epoch 01186: val_loss improved from 0.05913 to 0.05849, saving model to ./model/1186-0.0585.hdf5\n","\n","Epoch 01187: val_loss did not improve from 0.05849\n","\n","Epoch 01188: val_loss did not improve from 0.05849\n","\n","Epoch 01189: val_loss did not improve from 0.05849\n","\n","Epoch 01190: val_loss did not improve from 0.05849\n","\n","Epoch 01191: val_loss did not improve from 0.05849\n","\n","Epoch 01192: val_loss did not improve from 0.05849\n","\n","Epoch 01193: val_loss did not improve from 0.05849\n","\n","Epoch 01194: val_loss did not improve from 0.05849\n","\n","Epoch 01195: val_loss did not improve from 0.05849\n","\n","Epoch 01196: val_loss did not improve from 0.05849\n","\n","Epoch 01197: val_loss did not improve from 0.05849\n","\n","Epoch 01198: val_loss did not improve from 0.05849\n","\n","Epoch 01199: val_loss did not improve from 0.05849\n","\n","Epoch 01200: val_loss did not improve from 0.05849\n","\n","Epoch 01201: val_loss did not improve from 0.05849\n","\n","Epoch 01202: val_loss did not improve from 0.05849\n","\n","Epoch 01203: val_loss did not improve from 0.05849\n","\n","Epoch 01204: val_loss did not improve from 0.05849\n","\n","Epoch 01205: val_loss did not improve from 0.05849\n","\n","Epoch 01206: val_loss did not improve from 0.05849\n","\n","Epoch 01207: val_loss did not improve from 0.05849\n","\n","Epoch 01208: val_loss did not improve from 0.05849\n","\n","Epoch 01209: val_loss did not improve from 0.05849\n","\n","Epoch 01210: val_loss did not improve from 0.05849\n","\n","Epoch 01211: val_loss did not improve from 0.05849\n","\n","Epoch 01212: val_loss did not improve from 0.05849\n","\n","Epoch 01213: val_loss did not improve from 0.05849\n","\n","Epoch 01214: val_loss did not improve from 0.05849\n","\n","Epoch 01215: val_loss did not improve from 0.05849\n","\n","Epoch 01216: val_loss did not improve from 0.05849\n","\n","Epoch 01217: val_loss did not improve from 0.05849\n","\n","Epoch 01218: val_loss did not improve from 0.05849\n","\n","Epoch 01219: val_loss did not improve from 0.05849\n","\n","Epoch 01220: val_loss did not improve from 0.05849\n","\n","Epoch 01221: val_loss did not improve from 0.05849\n","\n","Epoch 01222: val_loss did not improve from 0.05849\n","\n","Epoch 01223: val_loss did not improve from 0.05849\n","\n","Epoch 01224: val_loss did not improve from 0.05849\n","\n","Epoch 01225: val_loss did not improve from 0.05849\n","\n","Epoch 01226: val_loss did not improve from 0.05849\n","\n","Epoch 01227: val_loss did not improve from 0.05849\n","\n","Epoch 01228: val_loss did not improve from 0.05849\n","\n","Epoch 01229: val_loss did not improve from 0.05849\n","\n","Epoch 01230: val_loss did not improve from 0.05849\n","\n","Epoch 01231: val_loss did not improve from 0.05849\n","\n","Epoch 01232: val_loss did not improve from 0.05849\n","\n","Epoch 01233: val_loss did not improve from 0.05849\n","\n","Epoch 01234: val_loss did not improve from 0.05849\n","\n","Epoch 01235: val_loss did not improve from 0.05849\n","\n","Epoch 01236: val_loss did not improve from 0.05849\n","\n","Epoch 01237: val_loss did not improve from 0.05849\n","\n","Epoch 01238: val_loss did not improve from 0.05849\n","\n","Epoch 01239: val_loss did not improve from 0.05849\n","\n","Epoch 01240: val_loss did not improve from 0.05849\n","\n","Epoch 01241: val_loss did not improve from 0.05849\n","\n","Epoch 01242: val_loss did not improve from 0.05849\n","\n","Epoch 01243: val_loss did not improve from 0.05849\n","\n","Epoch 01244: val_loss did not improve from 0.05849\n","\n","Epoch 01245: val_loss did not improve from 0.05849\n","\n","Epoch 01246: val_loss did not improve from 0.05849\n","\n","Epoch 01247: val_loss did not improve from 0.05849\n","\n","Epoch 01248: val_loss did not improve from 0.05849\n","\n","Epoch 01249: val_loss did not improve from 0.05849\n","\n","Epoch 01250: val_loss did not improve from 0.05849\n","\n","Epoch 01251: val_loss did not improve from 0.05849\n","\n","Epoch 01252: val_loss did not improve from 0.05849\n","\n","Epoch 01253: val_loss did not improve from 0.05849\n","\n","Epoch 01254: val_loss did not improve from 0.05849\n","\n","Epoch 01255: val_loss did not improve from 0.05849\n","\n","Epoch 01256: val_loss did not improve from 0.05849\n","\n","Epoch 01257: val_loss did not improve from 0.05849\n","\n","Epoch 01258: val_loss did not improve from 0.05849\n","\n","Epoch 01259: val_loss improved from 0.05849 to 0.05824, saving model to ./model/1259-0.0582.hdf5\n","\n","Epoch 01260: val_loss did not improve from 0.05824\n","\n","Epoch 01261: val_loss did not improve from 0.05824\n","\n","Epoch 01262: val_loss did not improve from 0.05824\n","\n","Epoch 01263: val_loss did not improve from 0.05824\n","\n","Epoch 01264: val_loss did not improve from 0.05824\n","\n","Epoch 01265: val_loss did not improve from 0.05824\n","\n","Epoch 01266: val_loss did not improve from 0.05824\n","\n","Epoch 01267: val_loss did not improve from 0.05824\n","\n","Epoch 01268: val_loss did not improve from 0.05824\n","\n","Epoch 01269: val_loss did not improve from 0.05824\n","\n","Epoch 01270: val_loss did not improve from 0.05824\n","\n","Epoch 01271: val_loss improved from 0.05824 to 0.05742, saving model to ./model/1271-0.0574.hdf5\n","\n","Epoch 01272: val_loss did not improve from 0.05742\n","\n","Epoch 01273: val_loss did not improve from 0.05742\n","\n","Epoch 01274: val_loss did not improve from 0.05742\n","\n","Epoch 01275: val_loss did not improve from 0.05742\n","\n","Epoch 01276: val_loss did not improve from 0.05742\n","\n","Epoch 01277: val_loss did not improve from 0.05742\n","\n","Epoch 01278: val_loss did not improve from 0.05742\n","\n","Epoch 01279: val_loss did not improve from 0.05742\n","\n","Epoch 01280: val_loss did not improve from 0.05742\n","\n","Epoch 01281: val_loss did not improve from 0.05742\n","\n","Epoch 01282: val_loss did not improve from 0.05742\n","\n","Epoch 01283: val_loss did not improve from 0.05742\n","\n","Epoch 01284: val_loss did not improve from 0.05742\n","\n","Epoch 01285: val_loss did not improve from 0.05742\n","\n","Epoch 01286: val_loss did not improve from 0.05742\n","\n","Epoch 01287: val_loss did not improve from 0.05742\n","\n","Epoch 01288: val_loss did not improve from 0.05742\n","\n","Epoch 01289: val_loss did not improve from 0.05742\n","\n","Epoch 01290: val_loss did not improve from 0.05742\n","\n","Epoch 01291: val_loss did not improve from 0.05742\n","\n","Epoch 01292: val_loss did not improve from 0.05742\n","\n","Epoch 01293: val_loss did not improve from 0.05742\n","\n","Epoch 01294: val_loss did not improve from 0.05742\n","\n","Epoch 01295: val_loss did not improve from 0.05742\n","\n","Epoch 01296: val_loss did not improve from 0.05742\n","\n","Epoch 01297: val_loss did not improve from 0.05742\n","\n","Epoch 01298: val_loss did not improve from 0.05742\n","\n","Epoch 01299: val_loss did not improve from 0.05742\n","\n","Epoch 01300: val_loss did not improve from 0.05742\n","\n","Epoch 01301: val_loss did not improve from 0.05742\n","\n","Epoch 01302: val_loss did not improve from 0.05742\n","\n","Epoch 01303: val_loss did not improve from 0.05742\n","\n","Epoch 01304: val_loss did not improve from 0.05742\n","\n","Epoch 01305: val_loss did not improve from 0.05742\n","\n","Epoch 01306: val_loss did not improve from 0.05742\n","\n","Epoch 01307: val_loss did not improve from 0.05742\n","\n","Epoch 01308: val_loss did not improve from 0.05742\n","\n","Epoch 01309: val_loss did not improve from 0.05742\n","\n","Epoch 01310: val_loss did not improve from 0.05742\n","\n","Epoch 01311: val_loss did not improve from 0.05742\n","\n","Epoch 01312: val_loss did not improve from 0.05742\n","\n","Epoch 01313: val_loss did not improve from 0.05742\n","\n","Epoch 01314: val_loss did not improve from 0.05742\n","\n","Epoch 01315: val_loss did not improve from 0.05742\n","\n","Epoch 01316: val_loss did not improve from 0.05742\n","\n","Epoch 01317: val_loss did not improve from 0.05742\n","\n","Epoch 01318: val_loss did not improve from 0.05742\n","\n","Epoch 01319: val_loss did not improve from 0.05742\n","\n","Epoch 01320: val_loss did not improve from 0.05742\n","\n","Epoch 01321: val_loss did not improve from 0.05742\n","\n","Epoch 01322: val_loss did not improve from 0.05742\n","\n","Epoch 01323: val_loss did not improve from 0.05742\n","\n","Epoch 01324: val_loss did not improve from 0.05742\n","\n","Epoch 01325: val_loss did not improve from 0.05742\n","\n","Epoch 01326: val_loss did not improve from 0.05742\n","\n","Epoch 01327: val_loss did not improve from 0.05742\n","\n","Epoch 01328: val_loss did not improve from 0.05742\n","\n","Epoch 01329: val_loss did not improve from 0.05742\n","\n","Epoch 01330: val_loss did not improve from 0.05742\n","\n","Epoch 01331: val_loss did not improve from 0.05742\n","\n","Epoch 01332: val_loss did not improve from 0.05742\n","\n","Epoch 01333: val_loss did not improve from 0.05742\n","\n","Epoch 01334: val_loss did not improve from 0.05742\n","\n","Epoch 01335: val_loss did not improve from 0.05742\n","\n","Epoch 01336: val_loss did not improve from 0.05742\n","\n","Epoch 01337: val_loss did not improve from 0.05742\n","\n","Epoch 01338: val_loss did not improve from 0.05742\n","\n","Epoch 01339: val_loss did not improve from 0.05742\n","\n","Epoch 01340: val_loss did not improve from 0.05742\n","\n","Epoch 01341: val_loss did not improve from 0.05742\n","\n","Epoch 01342: val_loss did not improve from 0.05742\n","\n","Epoch 01343: val_loss improved from 0.05742 to 0.05735, saving model to ./model/1343-0.0573.hdf5\n","\n","Epoch 01344: val_loss did not improve from 0.05735\n","\n","Epoch 01345: val_loss did not improve from 0.05735\n","\n","Epoch 01346: val_loss improved from 0.05735 to 0.05622, saving model to ./model/1346-0.0562.hdf5\n","\n","Epoch 01347: val_loss did not improve from 0.05622\n","\n","Epoch 01348: val_loss did not improve from 0.05622\n","\n","Epoch 01349: val_loss did not improve from 0.05622\n","\n","Epoch 01350: val_loss did not improve from 0.05622\n","\n","Epoch 01351: val_loss did not improve from 0.05622\n","\n","Epoch 01352: val_loss did not improve from 0.05622\n","\n","Epoch 01353: val_loss did not improve from 0.05622\n","\n","Epoch 01354: val_loss did not improve from 0.05622\n","\n","Epoch 01355: val_loss did not improve from 0.05622\n","\n","Epoch 01356: val_loss did not improve from 0.05622\n","\n","Epoch 01357: val_loss did not improve from 0.05622\n","\n","Epoch 01358: val_loss did not improve from 0.05622\n","\n","Epoch 01359: val_loss did not improve from 0.05622\n","\n","Epoch 01360: val_loss did not improve from 0.05622\n","\n","Epoch 01361: val_loss did not improve from 0.05622\n","\n","Epoch 01362: val_loss did not improve from 0.05622\n","\n","Epoch 01363: val_loss did not improve from 0.05622\n","\n","Epoch 01364: val_loss did not improve from 0.05622\n","\n","Epoch 01365: val_loss did not improve from 0.05622\n","\n","Epoch 01366: val_loss did not improve from 0.05622\n","\n","Epoch 01367: val_loss did not improve from 0.05622\n","\n","Epoch 01368: val_loss did not improve from 0.05622\n","\n","Epoch 01369: val_loss did not improve from 0.05622\n","\n","Epoch 01370: val_loss did not improve from 0.05622\n","\n","Epoch 01371: val_loss did not improve from 0.05622\n","\n","Epoch 01372: val_loss did not improve from 0.05622\n","\n","Epoch 01373: val_loss did not improve from 0.05622\n","\n","Epoch 01374: val_loss did not improve from 0.05622\n","\n","Epoch 01375: val_loss did not improve from 0.05622\n","\n","Epoch 01376: val_loss did not improve from 0.05622\n","\n","Epoch 01377: val_loss did not improve from 0.05622\n","\n","Epoch 01378: val_loss did not improve from 0.05622\n","\n","Epoch 01379: val_loss did not improve from 0.05622\n","\n","Epoch 01380: val_loss did not improve from 0.05622\n","\n","Epoch 01381: val_loss did not improve from 0.05622\n","\n","Epoch 01382: val_loss did not improve from 0.05622\n","\n","Epoch 01383: val_loss did not improve from 0.05622\n","\n","Epoch 01384: val_loss did not improve from 0.05622\n","\n","Epoch 01385: val_loss did not improve from 0.05622\n","\n","Epoch 01386: val_loss did not improve from 0.05622\n","\n","Epoch 01387: val_loss did not improve from 0.05622\n","\n","Epoch 01388: val_loss did not improve from 0.05622\n","\n","Epoch 01389: val_loss did not improve from 0.05622\n","\n","Epoch 01390: val_loss did not improve from 0.05622\n","\n","Epoch 01391: val_loss did not improve from 0.05622\n","\n","Epoch 01392: val_loss did not improve from 0.05622\n","\n","Epoch 01393: val_loss did not improve from 0.05622\n","\n","Epoch 01394: val_loss improved from 0.05622 to 0.05607, saving model to ./model/1394-0.0561.hdf5\n","\n","Epoch 01395: val_loss did not improve from 0.05607\n","\n","Epoch 01396: val_loss did not improve from 0.05607\n","\n","Epoch 01397: val_loss did not improve from 0.05607\n","\n","Epoch 01398: val_loss improved from 0.05607 to 0.05424, saving model to ./model/1398-0.0542.hdf5\n","\n","Epoch 01399: val_loss did not improve from 0.05424\n","\n","Epoch 01400: val_loss did not improve from 0.05424\n","\n","Epoch 01401: val_loss did not improve from 0.05424\n","\n","Epoch 01402: val_loss did not improve from 0.05424\n","\n","Epoch 01403: val_loss did not improve from 0.05424\n","\n","Epoch 01404: val_loss did not improve from 0.05424\n","\n","Epoch 01405: val_loss did not improve from 0.05424\n","\n","Epoch 01406: val_loss did not improve from 0.05424\n","\n","Epoch 01407: val_loss did not improve from 0.05424\n","\n","Epoch 01408: val_loss did not improve from 0.05424\n","\n","Epoch 01409: val_loss did not improve from 0.05424\n","\n","Epoch 01410: val_loss did not improve from 0.05424\n","\n","Epoch 01411: val_loss did not improve from 0.05424\n","\n","Epoch 01412: val_loss did not improve from 0.05424\n","\n","Epoch 01413: val_loss did not improve from 0.05424\n","\n","Epoch 01414: val_loss did not improve from 0.05424\n","\n","Epoch 01415: val_loss did not improve from 0.05424\n","\n","Epoch 01416: val_loss did not improve from 0.05424\n","\n","Epoch 01417: val_loss did not improve from 0.05424\n","\n","Epoch 01418: val_loss did not improve from 0.05424\n","\n","Epoch 01419: val_loss did not improve from 0.05424\n","\n","Epoch 01420: val_loss did not improve from 0.05424\n","\n","Epoch 01421: val_loss did not improve from 0.05424\n","\n","Epoch 01422: val_loss did not improve from 0.05424\n","\n","Epoch 01423: val_loss did not improve from 0.05424\n","\n","Epoch 01424: val_loss did not improve from 0.05424\n","\n","Epoch 01425: val_loss did not improve from 0.05424\n","\n","Epoch 01426: val_loss did not improve from 0.05424\n","\n","Epoch 01427: val_loss did not improve from 0.05424\n","\n","Epoch 01428: val_loss did not improve from 0.05424\n","\n","Epoch 01429: val_loss did not improve from 0.05424\n","\n","Epoch 01430: val_loss did not improve from 0.05424\n","\n","Epoch 01431: val_loss did not improve from 0.05424\n","\n","Epoch 01432: val_loss did not improve from 0.05424\n","\n","Epoch 01433: val_loss improved from 0.05424 to 0.05409, saving model to ./model/1433-0.0541.hdf5\n","\n","Epoch 01434: val_loss did not improve from 0.05409\n","\n","Epoch 01435: val_loss did not improve from 0.05409\n","\n","Epoch 01436: val_loss did not improve from 0.05409\n","\n","Epoch 01437: val_loss did not improve from 0.05409\n","\n","Epoch 01438: val_loss did not improve from 0.05409\n","\n","Epoch 01439: val_loss did not improve from 0.05409\n","\n","Epoch 01440: val_loss did not improve from 0.05409\n","\n","Epoch 01441: val_loss did not improve from 0.05409\n","\n","Epoch 01442: val_loss did not improve from 0.05409\n","\n","Epoch 01443: val_loss did not improve from 0.05409\n","\n","Epoch 01444: val_loss did not improve from 0.05409\n","\n","Epoch 01445: val_loss did not improve from 0.05409\n","\n","Epoch 01446: val_loss did not improve from 0.05409\n","\n","Epoch 01447: val_loss did not improve from 0.05409\n","\n","Epoch 01448: val_loss did not improve from 0.05409\n","\n","Epoch 01449: val_loss did not improve from 0.05409\n","\n","Epoch 01450: val_loss did not improve from 0.05409\n","\n","Epoch 01451: val_loss did not improve from 0.05409\n","\n","Epoch 01452: val_loss did not improve from 0.05409\n","\n","Epoch 01453: val_loss did not improve from 0.05409\n","\n","Epoch 01454: val_loss did not improve from 0.05409\n","\n","Epoch 01455: val_loss did not improve from 0.05409\n","\n","Epoch 01456: val_loss did not improve from 0.05409\n","\n","Epoch 01457: val_loss did not improve from 0.05409\n","\n","Epoch 01458: val_loss did not improve from 0.05409\n","\n","Epoch 01459: val_loss did not improve from 0.05409\n","\n","Epoch 01460: val_loss did not improve from 0.05409\n","\n","Epoch 01461: val_loss did not improve from 0.05409\n","\n","Epoch 01462: val_loss did not improve from 0.05409\n","\n","Epoch 01463: val_loss did not improve from 0.05409\n","\n","Epoch 01464: val_loss did not improve from 0.05409\n","\n","Epoch 01465: val_loss did not improve from 0.05409\n","\n","Epoch 01466: val_loss did not improve from 0.05409\n","\n","Epoch 01467: val_loss did not improve from 0.05409\n","\n","Epoch 01468: val_loss did not improve from 0.05409\n","\n","Epoch 01469: val_loss did not improve from 0.05409\n","\n","Epoch 01470: val_loss did not improve from 0.05409\n","\n","Epoch 01471: val_loss did not improve from 0.05409\n","\n","Epoch 01472: val_loss did not improve from 0.05409\n","\n","Epoch 01473: val_loss did not improve from 0.05409\n","\n","Epoch 01474: val_loss did not improve from 0.05409\n","\n","Epoch 01475: val_loss did not improve from 0.05409\n","\n","Epoch 01476: val_loss did not improve from 0.05409\n","\n","Epoch 01477: val_loss did not improve from 0.05409\n","\n","Epoch 01478: val_loss did not improve from 0.05409\n","\n","Epoch 01479: val_loss did not improve from 0.05409\n","\n","Epoch 01480: val_loss did not improve from 0.05409\n","\n","Epoch 01481: val_loss did not improve from 0.05409\n","\n","Epoch 01482: val_loss did not improve from 0.05409\n","\n","Epoch 01483: val_loss did not improve from 0.05409\n","\n","Epoch 01484: val_loss did not improve from 0.05409\n","\n","Epoch 01485: val_loss did not improve from 0.05409\n","\n","Epoch 01486: val_loss did not improve from 0.05409\n","\n","Epoch 01487: val_loss did not improve from 0.05409\n","\n","Epoch 01488: val_loss did not improve from 0.05409\n","\n","Epoch 01489: val_loss did not improve from 0.05409\n","\n","Epoch 01490: val_loss did not improve from 0.05409\n","\n","Epoch 01491: val_loss did not improve from 0.05409\n","\n","Epoch 01492: val_loss did not improve from 0.05409\n","\n","Epoch 01493: val_loss did not improve from 0.05409\n","\n","Epoch 01494: val_loss did not improve from 0.05409\n","\n","Epoch 01495: val_loss did not improve from 0.05409\n","\n","Epoch 01496: val_loss did not improve from 0.05409\n","\n","Epoch 01497: val_loss did not improve from 0.05409\n","\n","Epoch 01498: val_loss did not improve from 0.05409\n","\n","Epoch 01499: val_loss did not improve from 0.05409\n","\n","Epoch 01500: val_loss did not improve from 0.05409\n","\n","Epoch 01501: val_loss did not improve from 0.05409\n","\n","Epoch 01502: val_loss did not improve from 0.05409\n","\n","Epoch 01503: val_loss did not improve from 0.05409\n","\n","Epoch 01504: val_loss did not improve from 0.05409\n","\n","Epoch 01505: val_loss did not improve from 0.05409\n","\n","Epoch 01506: val_loss did not improve from 0.05409\n","\n","Epoch 01507: val_loss did not improve from 0.05409\n","\n","Epoch 01508: val_loss did not improve from 0.05409\n","\n","Epoch 01509: val_loss did not improve from 0.05409\n","\n","Epoch 01510: val_loss did not improve from 0.05409\n","\n","Epoch 01511: val_loss did not improve from 0.05409\n","\n","Epoch 01512: val_loss did not improve from 0.05409\n","\n","Epoch 01513: val_loss did not improve from 0.05409\n","\n","Epoch 01514: val_loss did not improve from 0.05409\n","\n","Epoch 01515: val_loss did not improve from 0.05409\n","\n","Epoch 01516: val_loss did not improve from 0.05409\n","\n","Epoch 01517: val_loss improved from 0.05409 to 0.05387, saving model to ./model/1517-0.0539.hdf5\n","\n","Epoch 01518: val_loss did not improve from 0.05387\n","\n","Epoch 01519: val_loss did not improve from 0.05387\n","\n","Epoch 01520: val_loss did not improve from 0.05387\n","\n","Epoch 01521: val_loss did not improve from 0.05387\n","\n","Epoch 01522: val_loss did not improve from 0.05387\n","\n","Epoch 01523: val_loss improved from 0.05387 to 0.05338, saving model to ./model/1523-0.0534.hdf5\n","\n","Epoch 01524: val_loss did not improve from 0.05338\n","\n","Epoch 01525: val_loss did not improve from 0.05338\n","\n","Epoch 01526: val_loss improved from 0.05338 to 0.05308, saving model to ./model/1526-0.0531.hdf5\n","\n","Epoch 01527: val_loss did not improve from 0.05308\n","\n","Epoch 01528: val_loss did not improve from 0.05308\n","\n","Epoch 01529: val_loss did not improve from 0.05308\n","\n","Epoch 01530: val_loss did not improve from 0.05308\n","\n","Epoch 01531: val_loss did not improve from 0.05308\n","\n","Epoch 01532: val_loss did not improve from 0.05308\n","\n","Epoch 01533: val_loss did not improve from 0.05308\n","\n","Epoch 01534: val_loss did not improve from 0.05308\n","\n","Epoch 01535: val_loss did not improve from 0.05308\n","\n","Epoch 01536: val_loss did not improve from 0.05308\n","\n","Epoch 01537: val_loss improved from 0.05308 to 0.05118, saving model to ./model/1537-0.0512.hdf5\n","\n","Epoch 01538: val_loss did not improve from 0.05118\n","\n","Epoch 01539: val_loss did not improve from 0.05118\n","\n","Epoch 01540: val_loss did not improve from 0.05118\n","\n","Epoch 01541: val_loss did not improve from 0.05118\n","\n","Epoch 01542: val_loss did not improve from 0.05118\n","\n","Epoch 01543: val_loss did not improve from 0.05118\n","\n","Epoch 01544: val_loss did not improve from 0.05118\n","\n","Epoch 01545: val_loss did not improve from 0.05118\n","\n","Epoch 01546: val_loss did not improve from 0.05118\n","\n","Epoch 01547: val_loss did not improve from 0.05118\n","\n","Epoch 01548: val_loss did not improve from 0.05118\n","\n","Epoch 01549: val_loss did not improve from 0.05118\n","\n","Epoch 01550: val_loss did not improve from 0.05118\n","\n","Epoch 01551: val_loss did not improve from 0.05118\n","\n","Epoch 01552: val_loss did not improve from 0.05118\n","\n","Epoch 01553: val_loss did not improve from 0.05118\n","\n","Epoch 01554: val_loss did not improve from 0.05118\n","\n","Epoch 01555: val_loss did not improve from 0.05118\n","\n","Epoch 01556: val_loss did not improve from 0.05118\n","\n","Epoch 01557: val_loss improved from 0.05118 to 0.05023, saving model to ./model/1557-0.0502.hdf5\n","\n","Epoch 01558: val_loss did not improve from 0.05023\n","\n","Epoch 01559: val_loss did not improve from 0.05023\n","\n","Epoch 01560: val_loss did not improve from 0.05023\n","\n","Epoch 01561: val_loss did not improve from 0.05023\n","\n","Epoch 01562: val_loss did not improve from 0.05023\n","\n","Epoch 01563: val_loss did not improve from 0.05023\n","\n","Epoch 01564: val_loss did not improve from 0.05023\n","\n","Epoch 01565: val_loss improved from 0.05023 to 0.04884, saving model to ./model/1565-0.0488.hdf5\n","\n","Epoch 01566: val_loss did not improve from 0.04884\n","\n","Epoch 01567: val_loss did not improve from 0.04884\n","\n","Epoch 01568: val_loss did not improve from 0.04884\n","\n","Epoch 01569: val_loss did not improve from 0.04884\n","\n","Epoch 01570: val_loss did not improve from 0.04884\n","\n","Epoch 01571: val_loss did not improve from 0.04884\n","\n","Epoch 01572: val_loss did not improve from 0.04884\n","\n","Epoch 01573: val_loss did not improve from 0.04884\n","\n","Epoch 01574: val_loss did not improve from 0.04884\n","\n","Epoch 01575: val_loss did not improve from 0.04884\n","\n","Epoch 01576: val_loss did not improve from 0.04884\n","\n","Epoch 01577: val_loss did not improve from 0.04884\n","\n","Epoch 01578: val_loss did not improve from 0.04884\n","\n","Epoch 01579: val_loss did not improve from 0.04884\n","\n","Epoch 01580: val_loss did not improve from 0.04884\n","\n","Epoch 01581: val_loss did not improve from 0.04884\n","\n","Epoch 01582: val_loss did not improve from 0.04884\n","\n","Epoch 01583: val_loss did not improve from 0.04884\n","\n","Epoch 01584: val_loss did not improve from 0.04884\n","\n","Epoch 01585: val_loss did not improve from 0.04884\n","\n","Epoch 01586: val_loss did not improve from 0.04884\n","\n","Epoch 01587: val_loss did not improve from 0.04884\n","\n","Epoch 01588: val_loss did not improve from 0.04884\n","\n","Epoch 01589: val_loss did not improve from 0.04884\n","\n","Epoch 01590: val_loss did not improve from 0.04884\n","\n","Epoch 01591: val_loss did not improve from 0.04884\n","\n","Epoch 01592: val_loss did not improve from 0.04884\n","\n","Epoch 01593: val_loss did not improve from 0.04884\n","\n","Epoch 01594: val_loss did not improve from 0.04884\n","\n","Epoch 01595: val_loss did not improve from 0.04884\n","\n","Epoch 01596: val_loss did not improve from 0.04884\n","\n","Epoch 01597: val_loss did not improve from 0.04884\n","\n","Epoch 01598: val_loss did not improve from 0.04884\n","\n","Epoch 01599: val_loss did not improve from 0.04884\n","\n","Epoch 01600: val_loss did not improve from 0.04884\n","\n","Epoch 01601: val_loss did not improve from 0.04884\n","\n","Epoch 01602: val_loss did not improve from 0.04884\n","\n","Epoch 01603: val_loss did not improve from 0.04884\n","\n","Epoch 01604: val_loss did not improve from 0.04884\n","\n","Epoch 01605: val_loss did not improve from 0.04884\n","\n","Epoch 01606: val_loss did not improve from 0.04884\n","\n","Epoch 01607: val_loss did not improve from 0.04884\n","\n","Epoch 01608: val_loss did not improve from 0.04884\n","\n","Epoch 01609: val_loss did not improve from 0.04884\n","\n","Epoch 01610: val_loss did not improve from 0.04884\n","\n","Epoch 01611: val_loss did not improve from 0.04884\n","\n","Epoch 01612: val_loss did not improve from 0.04884\n","\n","Epoch 01613: val_loss did not improve from 0.04884\n","\n","Epoch 01614: val_loss did not improve from 0.04884\n","\n","Epoch 01615: val_loss did not improve from 0.04884\n","\n","Epoch 01616: val_loss did not improve from 0.04884\n","\n","Epoch 01617: val_loss did not improve from 0.04884\n","\n","Epoch 01618: val_loss did not improve from 0.04884\n","\n","Epoch 01619: val_loss did not improve from 0.04884\n","\n","Epoch 01620: val_loss did not improve from 0.04884\n","\n","Epoch 01621: val_loss did not improve from 0.04884\n","\n","Epoch 01622: val_loss did not improve from 0.04884\n","\n","Epoch 01623: val_loss did not improve from 0.04884\n","\n","Epoch 01624: val_loss did not improve from 0.04884\n","\n","Epoch 01625: val_loss did not improve from 0.04884\n","\n","Epoch 01626: val_loss did not improve from 0.04884\n","\n","Epoch 01627: val_loss did not improve from 0.04884\n","\n","Epoch 01628: val_loss did not improve from 0.04884\n","\n","Epoch 01629: val_loss did not improve from 0.04884\n","\n","Epoch 01630: val_loss did not improve from 0.04884\n","\n","Epoch 01631: val_loss did not improve from 0.04884\n","\n","Epoch 01632: val_loss did not improve from 0.04884\n","\n","Epoch 01633: val_loss did not improve from 0.04884\n","\n","Epoch 01634: val_loss did not improve from 0.04884\n","\n","Epoch 01635: val_loss did not improve from 0.04884\n","\n","Epoch 01636: val_loss did not improve from 0.04884\n","\n","Epoch 01637: val_loss did not improve from 0.04884\n","\n","Epoch 01638: val_loss did not improve from 0.04884\n","\n","Epoch 01639: val_loss did not improve from 0.04884\n","\n","Epoch 01640: val_loss did not improve from 0.04884\n","\n","Epoch 01641: val_loss did not improve from 0.04884\n","\n","Epoch 01642: val_loss did not improve from 0.04884\n","\n","Epoch 01643: val_loss did not improve from 0.04884\n","\n","Epoch 01644: val_loss did not improve from 0.04884\n","\n","Epoch 01645: val_loss did not improve from 0.04884\n","\n","Epoch 01646: val_loss did not improve from 0.04884\n","\n","Epoch 01647: val_loss did not improve from 0.04884\n","\n","Epoch 01648: val_loss did not improve from 0.04884\n","\n","Epoch 01649: val_loss did not improve from 0.04884\n","\n","Epoch 01650: val_loss did not improve from 0.04884\n","\n","Epoch 01651: val_loss did not improve from 0.04884\n","\n","Epoch 01652: val_loss did not improve from 0.04884\n","\n","Epoch 01653: val_loss did not improve from 0.04884\n","\n","Epoch 01654: val_loss did not improve from 0.04884\n","\n","Epoch 01655: val_loss did not improve from 0.04884\n","\n","Epoch 01656: val_loss did not improve from 0.04884\n","\n","Epoch 01657: val_loss did not improve from 0.04884\n","\n","Epoch 01658: val_loss did not improve from 0.04884\n","\n","Epoch 01659: val_loss did not improve from 0.04884\n","\n","Epoch 01660: val_loss did not improve from 0.04884\n","\n","Epoch 01661: val_loss did not improve from 0.04884\n","\n","Epoch 01662: val_loss did not improve from 0.04884\n","\n","Epoch 01663: val_loss did not improve from 0.04884\n","\n","Epoch 01664: val_loss did not improve from 0.04884\n","\n","Epoch 01665: val_loss did not improve from 0.04884\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f0867019eb8>"]},"metadata":{"tags":[]},"execution_count":2}]}]}